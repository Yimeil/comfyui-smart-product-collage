"""
ComfyUIæ‰¹é‡äº§å“æ‹¼æ¥èŠ‚ç‚¹ - å†…éƒ¨æŠ å›¾ç‰ˆ

åŠŸèƒ½ï¼š
- è¾“å…¥Nå¼ å›¾ç‰‡ï¼Œè‡ªåŠ¨æŒ‰æŒ‡å®šæ•°é‡åˆ†ç»„
- å†…éƒ¨æ™ºèƒ½æŠ å›¾ï¼Œä¿ç•™ä¸»ä½“å’Œé˜´å½±æ•ˆæœ
- æ¯ç»„è‡ªåŠ¨æ‹¼æ¥æˆä¸€å¼ ç™½åº•å›¾
- æ”¯æŒæ·»åŠ ä¸­æ–‡/æ•°å­—æ ‡ç­¾ï¼ˆæ ‡ç­¾åœ¨æ¯ç»„å†…å¾ªç¯ä½¿ç”¨ï¼‰
- æ”¯æŒé€—å·åˆ†éš”æˆ–æ¢è¡Œåˆ†éš”çš„æ ‡ç­¾è¾“å…¥
- æ™ºèƒ½ä¸»æ¬¡å¸ƒå±€ï¼ˆå¤§äº§å“è‡ªåŠ¨å•ç‹¬ä¸€ä¾§ï¼‰
- è¾“å‡ºæ‰€æœ‰æ‹¼æ¥åçš„å›¾ç‰‡

æ ¸å¿ƒç‰¹æ€§ï¼š
- å†…éƒ¨æŠ å›¾ç®—æ³•ï¼Œæ— éœ€å¤–éƒ¨mask
- æ™ºèƒ½ä¿ç•™äº§å“é˜´å½±ï¼Œæ•ˆæœæ›´è‡ªç„¶
- å¤šæ–¹æ³•èåˆï¼šè¾¹ç¼˜æ£€æµ‹ã€é˜ˆå€¼åˆ†å‰²ã€é¢œè‰²å·®å¼‚
- è½¯è¾¹ç¼˜å¤„ç†ï¼Œè¿‡æ¸¡æ›´æŸ”å’Œ

ä½¿ç”¨åœºæ™¯ï¼š
- 100å¼ å›¾ â†’ æ¯2å¼ æ‹¼æ¥ â†’ è¾“å‡º50å¼ æ‹¼æ¥å›¾
- 90å¼ å›¾ â†’ æ¯3å¼ æ‹¼æ¥ â†’ è¾“å‡º30å¼ æ‹¼æ¥å›¾
- æ”¯æŒä¸ºæ¯ç»„ä¸­çš„äº§å“æ·»åŠ æ ‡ç­¾ï¼ˆå¦‚ï¼šç¬¬1ä¸ªäº§å“7pcsã€ç¬¬2ä¸ªäº§å“5pcsï¼‰

æ ‡ç­¾é€»è¾‘ï¼š
- æ ‡ç­¾æ•°é‡ = æ¯ç»„å›¾ç‰‡æ•°é‡ï¼ˆimages_per_collageï¼‰
- æ¯ç»„éƒ½ä½¿ç”¨ç›¸åŒçš„æ ‡ç­¾
- ä¾‹å¦‚ï¼šæ¯ç»„2å¼ ï¼Œæ ‡ç­¾ä¸º"7pcs,5pcs"æˆ–"7pcs\n5pcs"ï¼Œåˆ™æ¯ç»„çš„ç¬¬1å¼ éƒ½æ˜¯7pcsï¼Œç¬¬2å¼ éƒ½æ˜¯5pcs

æ ‡ç­¾è¾“å…¥æ ¼å¼ï¼š
- é€—å·åˆ†éš”ï¼š7pcs,5pcs,3pcs ï¼ˆé€‚åˆç¨‹åºåŒ–ç”Ÿæˆï¼‰
- æ¢è¡Œåˆ†éš”ï¼š7pcs\n5pcs\n3pcs ï¼ˆé€‚åˆæ‰‹åŠ¨è¾“å…¥ï¼‰

ç‰ˆæœ¬: 2.0 (å†…éƒ¨æŠ å›¾ç‰ˆ - ä¿ç•™é˜´å½±)
æ—¥æœŸ: 2025-01-28
æ›´æ–°:
1. ç§»é™¤å¤–éƒ¨masksè¾“å…¥å‚æ•°
2. å®ç°å†…éƒ¨æ™ºèƒ½æŠ å›¾ç®—æ³•
3. ä¿ç•™äº§å“ä¸»ä½“å’Œé˜´å½±æ•ˆæœ
4. å¤šæ–¹æ³•èåˆæé«˜æŠ å›¾è´¨é‡
5. è½¯è¾¹ç¼˜å¤„ç†ï¼Œè¿‡æ¸¡æ›´è‡ªç„¶
6. ä¿æŒæ‰€æœ‰å…¶ä»–åŠŸèƒ½ä¸å˜
"""

import torch
import numpy as np
import cv2
from typing import List, Tuple
import math
import os
import re
from PIL import Image, ImageDraw, ImageFont



class SmartProductCollageBatch:
    """æ‰¹é‡äº§å“æ‹¼æ¥èŠ‚ç‚¹ - å†…éƒ¨æŠ å›¾ç‰ˆ"""

    def __init__(self):
        self.supported_fonts = [
            "arial.ttf",
            "simhei.ttf",
            "PingFang.ttc",
            "wqy-microhei.ttc",
            "msyh.ttf"
        ]
        # ç”¨äºå­˜å‚¨æ™ºèƒ½å¸ƒå±€æ—¶é€‰å®šçš„ä¸»äº§å“ç´¢å¼•
        self.forced_main_product_index = None

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),  # æ‰¹é‡è¾“å…¥
                "images_per_collage": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 9,
                    "step": 1,
                    "display": "number"
                }),
                "layout": ([
                    "auto",
                    "horizontal",
                    "vertical",
                    "grid",
                    "adaptive_focus",  # æ™ºèƒ½ä¸»æ¬¡å¸ƒå±€ï¼šå¤§å›¾å•ç‹¬ä¸€ä¾§
                ], {"default": "auto"}),
                "output_width": ("INT", {
                    "default": 1600,
                    "min": 512,
                    "max": 4096,
                    "step": 64
                }),
                "output_height": ("INT", {
                    "default": 1600,
                    "min": 512,
                    "max": 4096,
                    "step": 64
                }),
                "spacing": ("INT", {
                    "default": 60,
                    "min": 0,
                    "max": 200,
                    "step": 10
                }),
                "min_spacing": ("INT", {
                    "default": 10,
                    "min": 0,
                    "max": 50,
                    "step": 5,
                    "display": "number"
                }),
                "outer_padding": ("INT", {
                    "default": 80,
                    "min": 0,
                    "max": 300,
                    "step": 10
                }),
                "product_scale": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.3,
                    "max": 2.0,
                    "step": 0.05
                }),
                "crop_margin": ("INT", {
                    "default": 30,
                    "min": 0,
                    "max": 100,
                    "step": 5
                }),
            },
            "optional": {
                "skip_empty": ("BOOLEAN", {"default": True}),
                "labels": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "æ”¯æŒä¸¤ç§æ ¼å¼:\n1. é€—å·åˆ†éš”: 7pcs,5pcs,3pcs\n2. æ¢è¡Œåˆ†éš”:\n7pcs\n5pcs\n3pcs"
                }),
                "label_font_size": ("INT", {
                    "default": 180,
                    "min": 20,
                    "max": 500,
                    "step": 10
                }),
                "label_position": (["bottom", "top", "none"], {"default": "bottom"}),
                "label_margin": ("INT", {
                    "default": 40,
                    "min": 0,
                    "max": 200,
                    "step": 10
                }),
                "hide_pcs_one": ("BOOLEAN", {"default": False}),
                "adaptive_direction": (["auto", "left", "right", "top", "bottom"], {"default": "auto"}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("æ‹¼æ¥å›¾æ‰¹æ¬¡",)
    FUNCTION = "batch_collage"
    CATEGORY = "image/smart_collage"

    def tensor_to_cv2(self, tensor: torch.Tensor) -> np.ndarray:
        """Tensor â†’ OpenCV"""
        while len(tensor.shape) == 4 and tensor.shape[0] == 1:
            tensor = tensor[0]
        image = tensor.cpu().numpy()
        image = (image * 255).astype(np.uint8)
        return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

    def cv2_to_tensor(self, image: np.ndarray) -> torch.Tensor:
        """OpenCV â†’ Tensor"""
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = image.astype(np.float32) / 255.0
        tensor = torch.from_numpy(image)
        # æ·»åŠ batchç»´åº¦ [H, W, 3] â†’ [1, H, W, 3]
        return tensor.unsqueeze(0)

    def remove_background_with_shadow(self, image: np.ndarray, crop_margin: int) -> np.ndarray:
        """
        å†…éƒ¨æŠ å›¾æ–¹æ³• - ä¿ç•™æ‰€æœ‰ç‰©ä½“ï¼ˆä¸»ä½“+é…ä»¶ï¼‰å’Œé˜´å½±

        å‚æ•°:
            image: åŸå§‹å›¾ç‰‡ [H, W, 3]
            crop_margin: è£å‰ªè¾¹è·ç™¾åˆ†æ¯”

        è¿”å›:
            æŠ å‡ºçš„äº§å“å›¾ç‰‡ï¼ˆç™½åº•ï¼Œä¿ç•™æ‰€æœ‰ç‰©ä½“å’Œé˜´å½±ï¼‰[H, W, 3]
        """
        h, w = image.shape[:2]

        # 1. è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # 2. ä½¿ç”¨å¤šç§æ–¹æ³•æå–å‰æ™¯
        # æ–¹æ³•1: åŸºäºè¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 30, 100)
        edges_dilated = cv2.dilate(edges, np.ones((5, 5), np.uint8), iterations=2)

        # æ–¹æ³•2: åŸºäºé˜ˆå€¼ï¼ˆæ£€æµ‹éç™½è‰²åŒºåŸŸï¼‰
        # ä½¿ç”¨è¾ƒä½çš„é˜ˆå€¼ä»¥ä¿ç•™é˜´å½±
        _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)

        # æ–¹æ³•3: åŸºäºé¢œè‰²å·®å¼‚ï¼ˆæ£€æµ‹ä¸ç™½è‰²èƒŒæ™¯çš„å·®å¼‚ï¼‰
        # è®¡ç®—æ¯ä¸ªåƒç´ ä¸ç™½è‰²çš„å·®å¼‚
        white_bg = np.full_like(image, 255)
        color_diff = cv2.absdiff(image, white_bg)
        color_diff_gray = cv2.cvtColor(color_diff, cv2.COLOR_BGR2GRAY)
        _, color_mask = cv2.threshold(color_diff_gray, 10, 255, cv2.THRESH_BINARY)

        # 3. åˆå¹¶å¤šç§æ–¹æ³•çš„ç»“æœ
        combined_mask = cv2.bitwise_or(thresh, color_mask)
        combined_mask = cv2.bitwise_or(combined_mask, edges_dilated)

        # 4. å½¢æ€å­¦æ“ä½œï¼šé—­è¿ç®—å¡«å……å†…éƒ¨ç©ºæ´
        kernel = np.ones((15, 15), np.uint8)
        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)

        # 5. ğŸ†• æ‰¾åˆ°æ‰€æœ‰è¿é€šåŒºåŸŸï¼ˆä¿ç•™æ‰€æœ‰ç‰©ä½“ï¼ŒåŒ…æ‹¬é…ä»¶ï¼‰
        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è½®å»“ï¼Œè¿”å›åŸå›¾
            return image

        # ğŸ†• è¿‡æ»¤æ‰å¤ªå°çš„å™ªç‚¹ï¼Œä½†ä¿ç•™æ‰€æœ‰æœ‰æ•ˆç‰©ä½“
        # è®¡ç®—å›¾åƒæ€»é¢ç§¯
        total_area = h * w
        min_area_threshold = total_area * 0.0005  # è‡³å°‘æ˜¯å›¾åƒé¢ç§¯çš„0.05%ï¼Œè¿‡æ»¤å™ªç‚¹

        valid_contours = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > min_area_threshold:
                valid_contours.append(contour)

        if not valid_contours:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆè½®å»“ï¼Œè¿”å›åŸå›¾
            return image

        print(f"   ğŸ” æ£€æµ‹åˆ° {len(valid_contours)} ä¸ªç‰©ä½“")

        # 6. ğŸ†• åˆ›å»ºåŒ…å«æ‰€æœ‰ç‰©ä½“çš„mask
        # åˆ›å»ºç²¾ç»†çš„maskï¼ˆä¿ç•™é˜´å½±ï¼‰
        fine_mask = np.zeros((h, w), dtype=np.float32)

        # ğŸ†• ä¸ºæ‰€æœ‰æœ‰æ•ˆè½®å»“åˆ›å»ºmask
        all_contours_mask = np.zeros((h, w), dtype=np.uint8)
        cv2.drawContours(all_contours_mask, valid_contours, -1, 255, -1)

        # ğŸš€ å‘é‡åŒ–æ“ä½œï¼šåœ¨æ‰€æœ‰è½®å»“åŒºåŸŸå†…ï¼Œä¿ç•™é˜´å½±å’Œç»†èŠ‚
        # é˜´å½±åŒºåŸŸé€šå¸¸æ¯”ç™½è‰²èƒŒæ™¯æš—ï¼Œä½†æ¯”äº§å“ä¸»ä½“äº®
        # ä½¿ç”¨è‡ªé€‚åº”çš„é˜ˆå€¼æ¥åŒºåˆ†èƒŒæ™¯å’Œé˜´å½±

        # åˆ›å»ºmaskåŒºåŸŸçš„å¸ƒå°”ç´¢å¼•
        mask_region = all_contours_mask > 0

        # é˜´å½±ä¿ç•™ï¼š240ä»¥ä¸‹çš„éƒ½ä¿ç•™ï¼Œ240-255ä¹‹é—´æ¸å˜
        # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£åŒé‡å¾ªç¯ï¼Œé€Ÿåº¦æå‡100å€+
        fine_mask[mask_region & (gray < 240)] = 1.0
        fine_mask[mask_region & (gray >= 240)] = (255 - gray[mask_region & (gray >= 240)]) / 15.0

        # 7. é«˜æ–¯æ¨¡ç³Šä½¿è¾¹ç¼˜æ›´è‡ªç„¶
        fine_mask = cv2.GaussianBlur(fine_mask, (5, 5), 0)

        # 8. æ‰©å±•è¾¹ç•Œä»¥åŒ…å«æŸ”å’Œçš„é˜´å½±
        fine_mask_dilated = cv2.dilate((fine_mask * 255).astype(np.uint8),
                                        np.ones((7, 7), np.uint8), iterations=1)
        fine_mask = fine_mask_dilated.astype(np.float32) / 255.0

        # 9. ğŸ†• è®¡ç®—åŒ…å«æ‰€æœ‰ç‰©ä½“çš„è¾¹ç•Œæ¡†
        # åˆå¹¶æ‰€æœ‰æœ‰æ•ˆè½®å»“çš„è¾¹ç•Œæ¡†
        all_points = np.vstack(valid_contours)
        x, y, w_box, h_box = cv2.boundingRect(all_points)

        # æ·»åŠ è¾¹è·
        margin_x = int(w_box * crop_margin / 100)
        margin_y = int(h_box * crop_margin / 100)

        x = max(0, x - margin_x)
        y = max(0, y - margin_y)
        w_box = min(w - x, w_box + 2 * margin_x)
        h_box = min(h - y, h_box + 2 * margin_y)

        # è£å‰ªå›¾ç‰‡å’Œmask
        cropped_image = image[y:y+h_box, x:x+w_box]
        cropped_mask = fine_mask[y:y+h_box, x:x+w_box]

        # 10. åˆæˆåˆ°ç™½è‰²èƒŒæ™¯
        result = np.ones_like(cropped_image) * 255
        mask_3channel = np.stack([cropped_mask, cropped_mask, cropped_mask], axis=2)
        result = cropped_image * mask_3channel + result * (1 - mask_3channel)

        return result.astype(np.uint8)

    def calculate_circularity(self, product: np.ndarray) -> float:
        """
        è®¡ç®—äº§å“ä¸»ä½“çš„åœ†åº¦ï¼ˆåœ†å½¢åº¦ï¼‰

        è¿”å›: 0.0-1.0 çš„åœ†åº¦åˆ†æ•°
            - æ¥è¿‘1.0: å¾ˆåœ†ï¼ˆå¦‚æ‰‹é•¯ã€åœ†å½¢åŠå ï¼‰
            - æ¥è¿‘0.0: ä¸åœ†ï¼ˆå¦‚é“¾æ¡ã€ä¸è§„åˆ™å½¢çŠ¶ï¼‰
        """
        h, w = product.shape[:2]
        gray = cv2.cvtColor(product, cv2.COLOR_BGR2GRAY)
        mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)[1]

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return 0.0

        # é€‰æ‹©æœ€å¤§è½®å»“ï¼ˆä¸»ä½“ï¼‰
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)

        if area < 100:  # é¢ç§¯å¤ªå°ï¼Œæ— æ³•åˆ¤æ–­
            return 0.0

        # æ–¹æ³•1: åœ†å½¢åº¦ = 4Ï€ Ã— é¢ç§¯ / å‘¨é•¿Â²
        # å®Œç¾åœ†å½¢çš„å€¼ä¸º1.0ï¼Œå½¢çŠ¶è¶Šä¸è§„åˆ™å€¼è¶Šå°
        perimeter = cv2.arcLength(largest_contour, True)
        if perimeter == 0:
            return 0.0
        circularity = (4 * np.pi * area) / (perimeter ** 2)

        # æ–¹æ³•2: ä½¿ç”¨æœ€å°å¤–æ¥åœ†
        (x, y), radius = cv2.minEnclosingCircle(largest_contour)
        circle_area = np.pi * (radius ** 2)
        circle_fill_ratio = area / circle_area if circle_area > 0 else 0

        # æ–¹æ³•3: è½®å»“åˆ°è´¨å¿ƒçš„è·ç¦»æ–¹å·®ï¼ˆåœ†å½¢çš„è·ç¦»æ–¹å·®å¾ˆå°ï¼‰
        M = cv2.moments(largest_contour)
        if M['m00'] != 0:
            cx = int(M['m10'] / M['m00'])
            cy = int(M['m01'] / M['m00'])

            # è®¡ç®—æ‰€æœ‰è½®å»“ç‚¹åˆ°è´¨å¿ƒçš„è·ç¦»
            distances = []
            for point in largest_contour:
                px, py = point[0]
                dist = np.sqrt((px - cx) ** 2 + (py - cy) ** 2)
                distances.append(dist)

            if len(distances) > 0:
                # å½’ä¸€åŒ–æ ‡å‡†å·®ï¼ˆåœ†å½¢çš„æ ‡å‡†å·®æ¥è¿‘0ï¼‰
                mean_dist = np.mean(distances)
                std_dist = np.std(distances)
                normalized_std = std_dist / mean_dist if mean_dist > 0 else 1.0
                distance_uniformity = max(0, 1.0 - normalized_std)  # è¶Šæ¥è¿‘1è¶Šåœ†
            else:
                distance_uniformity = 0.0
        else:
            distance_uniformity = 0.0

        # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        final_circularity = (
            circularity * 0.4 +           # å‘¨é•¿é¢ç§¯æ¯”
            circle_fill_ratio * 0.3 +     # å¤–æ¥åœ†å¡«å……ç‡
            distance_uniformity * 0.3     # è·ç¦»å‡åŒ€æ€§
        )

        # é™åˆ¶åœ¨0-1èŒƒå›´
        final_circularity = max(0.0, min(1.0, final_circularity))

        return final_circularity

    def get_product_features(self, product: np.ndarray) -> Tuple[float, float, float, bool]:
        """
        ğŸ”§ ä¿®å¤3: æ”¹è¿›é“¾æ¡è¯†åˆ«ç®—æ³• - ä¼˜å…ˆè¯†åˆ«å¼€æ”¾æ€§é“¾æ¡

        è¿”å›: (area_ratio, aspect_ratio, edge_density, is_chain)
        """
        h, w = product.shape[:2]
        gray = cv2.cvtColor(product, cv2.COLOR_BGR2GRAY)

        # è®¡ç®—éç™½è‰²åŒºåŸŸé¢ç§¯
        mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)[1]
        area_ratio = np.sum(mask > 0) / (h * w)

        # å®½é«˜æ¯”
        aspect_ratio = w / h

        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 30, 100)
        edge_density = np.sum(edges > 0) / (h * w)

        # ğŸ”§ ä¿®å¤3: é“¾æ¡ç‰¹å¾æ£€æµ‹ - é‡ç‚¹æ£€æµ‹å¼€æ”¾æ€§é“¾æ¡
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        is_chain = False
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)

            # æ£€æµ‹å¼€æ”¾è¾¹ç¼˜ - é“¾æ¡é€šå¸¸æœ‰æ–­å¼€çš„éƒ¨åˆ†
            hull = cv2.convexHull(largest_contour)
            hull_area = cv2.contourArea(hull)
            contour_area = cv2.contourArea(largest_contour)
            solidity = contour_area / hull_area if hull_area > 0 else 0

            # è®¡ç®—è½®å»“çš„ç´§å¯†åº¦ï¼ˆå‘¨é•¿Â²/é¢ç§¯ï¼‰
            perimeter = cv2.arcLength(largest_contour, True)
            elongation_factor = (perimeter ** 2) / contour_area if contour_area > 0 else 0

            # æ£€æµ‹è¾¹ç•Œæ¥è§¦ - é“¾æ¡å¸¸å¸¸å»¶ä¼¸åˆ°å›¾åƒè¾¹ç¼˜
            x, y, w_box, h_box = cv2.boundingRect(largest_contour)
            touches_edge = (x <= 5 or y <= 5 or x + w_box >= w - 5 or y + h_box >= h - 5)

            # ğŸ”§ ä¿®å¤3: å¼€æ”¾æ€§æ£€æµ‹ - æ£€æµ‹è½®å»“çš„å¼€æ”¾ç¨‹åº¦
            # è®¡ç®—è½®å»“çš„å‡¸æ€§ç¼ºé™·
            defects = cv2.convexityDefects(largest_contour, cv2.convexHull(largest_contour, returnPoints=False))
            major_defects = 0
            if defects is not None:
                for i in range(defects.shape[0]):
                    s, e, f, d = defects[i, 0]
                    if d > 1000:  # è¾ƒå¤§çš„å‡¸æ€§ç¼ºé™·è¡¨ç¤ºå¼€æ”¾æ€§
                        major_defects += 1

            # ğŸ”§ ä¿®å¤3: é“¾æ¡åˆ¤æ–­æ¡ä»¶ï¼ˆé’ˆå¯¹é¦–é¥°ç±»äº§å“ä¼˜åŒ–ï¼‰
            chain_score = 0

            # 1. å¼€æ”¾æ€§ç‰¹å¾ï¼ˆæœ€é‡è¦ï¼‰
            if major_defects >= 2:  # æœ‰å¤šä¸ªæ˜æ˜¾çš„å¼€å£/å‡¹é™·
                chain_score += 4
            elif major_defects >= 1:
                chain_score += 2

            # 2. ç»†é•¿ç‰¹å¾
            if elongation_factor > 20:  # æåº¦ç»†é•¿
                chain_score += 3
            elif elongation_factor > 15:
                chain_score += 2

            # 3. ä½å¯†å®åº¦ï¼ˆæœ‰å¾ˆå¤šç©ºéš™ï¼‰
            if solidity < 0.7:
                chain_score += 2
            elif solidity < 0.8:
                chain_score += 1

            # 4. æ¥è§¦è¾¹ç¼˜
            if touches_edge:
                chain_score += 2

            # 5. å®½é«˜æ¯”ç‰¹å¾ï¼ˆé¦–é¥°é“¾æ¡é€šå¸¸å¾ˆé•¿ï¼‰
            if aspect_ratio > 2.5 or aspect_ratio < 0.4:
                chain_score += 2
            elif aspect_ratio > 1.8 or aspect_ratio < 0.6:
                chain_score += 1

            # 6. ä½é¢ç§¯ä½†é«˜è¾¹ç¼˜å¯†åº¦ï¼ˆç»†é“¾æ¡ç‰¹å¾ï¼‰
            if area_ratio < 0.15 and edge_density > 0.08:
                chain_score += 2
            elif area_ratio < 0.25 and edge_density > 0.06:
                chain_score += 1

            # ğŸ”§ ä¿®å¤3: é™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“è¯†åˆ«å¼€æ”¾æ€§é“¾æ¡
            is_chain = chain_score >= 4  # ä»5é™ä½åˆ°4ï¼Œæ›´å®¹æ˜“è¯†åˆ«é“¾æ¡

            print(f"     é“¾æ¡æ£€æµ‹: ç»†é•¿åº¦={elongation_factor:.1f}, å¯†å®åº¦={solidity:.3f}, "
                  f"å¼€æ”¾ç¼ºé™·={major_defects}, æ¥è§¦è¾¹ç¼˜={touches_edge}, å¾—åˆ†={chain_score}, "
                  f"åˆ¤å®š={'å¼€æ”¾é“¾æ¡' if is_chain else 'éé“¾æ¡'}")

        return area_ratio, aspect_ratio, edge_density, is_chain

    def calculate_product_similarity(self, product1: np.ndarray, product2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªäº§å“çš„ç›¸ä¼¼åº¦ï¼ˆåŸºäºå½¢çŠ¶è€Œéé¢œè‰²ï¼‰

        è¿”å›: 0.0-1.0 çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œ1.0è¡¨ç¤ºå®Œå…¨ç›¸åŒ
        """
        # è°ƒæ•´å¤§å°åˆ°ç›¸åŒå°ºå¯¸ä»¥ä¾¿æ¯”è¾ƒ
        h1, w1 = product1.shape[:2]
        h2, w2 = product2.shape[:2]
        target_size = (200, 200)  # ç»Ÿä¸€å°ºå¯¸

        resized1 = cv2.resize(product1, target_size, interpolation=cv2.INTER_AREA)
        resized2 = cv2.resize(product2, target_size, interpolation=cv2.INTER_AREA)

        # æå–maskï¼ˆç”¨äºå½¢çŠ¶æ¯”è¾ƒï¼‰
        gray1 = cv2.cvtColor(resized1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(resized2, cv2.COLOR_BGR2GRAY)
        mask1 = cv2.threshold(gray1, 240, 255, cv2.THRESH_BINARY_INV)[1]
        mask2 = cv2.threshold(gray2, 240, 255, cv2.THRESH_BINARY_INV)[1]

        # æ–¹æ³•1: å½¢çŠ¶ç›¸ä¼¼åº¦ï¼ˆHuçŸ©ï¼‰- 40%æƒé‡
        # HuçŸ©æ˜¯å½¢çŠ¶çš„7ä¸ªä¸å˜ç‰¹å¾ï¼Œä¸å—é¢œè‰²ã€å°ºåº¦ã€æ—‹è½¬å½±å“
        contours1, _ = cv2.findContours(mask1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        contours2, _ = cv2.findContours(mask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        shape_similarity = 0.0
        if contours1 and contours2:
            # é€‰æ‹©æœ€å¤§è½®å»“
            contour1 = max(contours1, key=cv2.contourArea)
            contour2 = max(contours2, key=cv2.contourArea)

            # è®¡ç®—HuçŸ©
            hu1 = cv2.HuMoments(cv2.moments(contour1)).flatten()
            hu2 = cv2.HuMoments(cv2.moments(contour2)).flatten()

            # ä½¿ç”¨å¯¹æ•°å°ºåº¦æ¯”è¾ƒï¼ˆHuçŸ©å€¼èŒƒå›´å¾ˆå¤§ï¼‰
            hu1_log = -np.sign(hu1) * np.log10(np.abs(hu1) + 1e-10)
            hu2_log = -np.sign(hu2) * np.log10(np.abs(hu2) + 1e-10)

            # è®¡ç®—æ¬§æ°è·ç¦»å¹¶å½’ä¸€åŒ–åˆ°0-1
            hu_distance = np.linalg.norm(hu1_log - hu2_log)
            shape_similarity = max(0.0, 1.0 - hu_distance / 10.0)  # è·ç¦»è¶Šå°ç›¸ä¼¼åº¦è¶Šé«˜

        # æ–¹æ³•2: Maské‡å åº¦ï¼ˆIoUï¼‰- 35%æƒé‡
        intersection = np.logical_and(mask1 > 0, mask2 > 0)
        union = np.logical_or(mask1 > 0, mask2 > 0)
        iou = np.sum(intersection) / np.sum(union) if np.sum(union) > 0 else 0.0

        # æ–¹æ³•3: è¾¹ç¼˜ç›¸ä¼¼åº¦ï¼ˆåŸºäºCannyè¾¹ç¼˜æ£€æµ‹ï¼‰- 15%æƒé‡
        edges1 = cv2.Canny(mask1, 50, 150)
        edges2 = cv2.Canny(mask2, 50, 150)
        edge_diff = cv2.absdiff(edges1, edges2)
        edge_similarity = 1.0 - (np.sum(edge_diff > 0) / (target_size[0] * target_size[1]))

        # æ–¹æ³•4: å®½é«˜æ¯”ç›¸ä¼¼åº¦ - 10%æƒé‡
        aspect1 = w1 / h1 if h1 > 0 else 1.0
        aspect2 = w2 / h2 if h2 > 0 else 1.0
        aspect_similarity = 1.0 - min(abs(aspect1 - aspect2) / max(aspect1, aspect2), 1.0)

        # ç»¼åˆç›¸ä¼¼åº¦ï¼ˆåŠ æƒå¹³å‡ï¼Œä¾§é‡å½¢çŠ¶ç‰¹å¾ï¼‰
        similarity = (
            shape_similarity * 0.40 +    # HuçŸ©å½¢çŠ¶åŒ¹é…
            iou * 0.35 +                  # Maské‡å åº¦
            edge_similarity * 0.15 +      # è¾¹ç¼˜ç›¸ä¼¼åº¦
            aspect_similarity * 0.10      # å®½é«˜æ¯”
        )

        return max(0.0, min(1.0, similarity))

    def detect_duplicate_products(self, products: List[np.ndarray], threshold: float = 0.85) -> bool:
        """
        æ£€æµ‹æ˜¯å¦æ‰€æœ‰äº§å“éƒ½æ˜¯é‡å¤çš„ï¼ˆç›¸ä¼¼åº¦é«˜ï¼‰

        å‚æ•°:
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé«˜äºæ­¤å€¼è®¤ä¸ºæ˜¯é‡å¤äº§å“

        è¿”å›:
            True å¦‚æœæ‰€æœ‰äº§å“éƒ½ç›¸ä¼¼ï¼ˆé‡å¤ï¼‰
        """
        if len(products) <= 1:
            return False

        # è®¡ç®—æ‰€æœ‰äº§å“ä¹‹é—´çš„ç›¸ä¼¼åº¦
        similarities = []
        for i in range(len(products)):
            for j in range(i + 1, len(products)):
                similarity = self.calculate_product_similarity(products[i], products[j])
                similarities.append(similarity)

        if not similarities:
            return False

        # æ‰€æœ‰äº§å“å¯¹çš„å¹³å‡ç›¸ä¼¼åº¦
        avg_similarity = np.mean(similarities)
        min_similarity = np.min(similarities)

        # åˆ¤æ–­æ ‡å‡†ï¼šå¹³å‡ç›¸ä¼¼åº¦é«˜ä¸”æœ€ä½ç›¸ä¼¼åº¦ä¹Ÿé«˜
        is_duplicate = avg_similarity > threshold and min_similarity > (threshold - 0.1)

        if is_duplicate:
            print(f"   ğŸ” æ£€æµ‹åˆ°é‡å¤äº§å“ (å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.2f}, æœ€ä½: {min_similarity:.2f})")

        return is_duplicate

    def decide_layout(self, num_products: int, layout: str, products: List[np.ndarray] = None) -> str:
        """
        å†³å®šå¸ƒå±€æ–¹å¼

        Args:
            num_products: å›¾ç‰‡æ•°é‡
            layout: ç”¨æˆ·é€‰æ‹©çš„å¸ƒå±€æ¨¡å¼
            products: äº§å“å›¾ç‰‡åˆ—è¡¨ï¼ˆç”¨äºæ™ºèƒ½åˆ¤æ–­ï¼‰

        Returns:
            æœ€ç»ˆå¸ƒå±€æ¨¡å¼
        """
        if layout != "auto" and layout != "adaptive_focus":
            return layout

        # auto: è‡ªåŠ¨é€‰æ‹©
        if num_products == 1:
            return "single"

        if num_products == 2:
            return "horizontal"

        if num_products > 3:
            return "grid"

        # ğŸ”§ åªæœ‰æ•°é‡ç­‰äº3æ—¶ï¼Œæ‰æ£€æµ‹é“¾æ¡æ¥å†³å®šæ˜¯å¦ä½¿ç”¨ adaptive_focus
        if products and layout == "auto" and num_products == 3:
            chain_products = []  # å­˜å‚¨æ‰€æœ‰é“¾æ¡äº§å“çš„ä¿¡æ¯

            for idx, p in enumerate(products):
                h, w = p.shape[:2]

                # ğŸ¯ æ ¸å¿ƒé€»è¾‘ï¼šç›´æ¥ä½¿ç”¨åœ†åº¦åˆ¤æ–­æ˜¯å¦ä¸ºé—­åˆç¯
                circularity = self.calculate_circularity(p)

                # ğŸ”§ ç®€åŒ–çš„é“¾æ¡ç‰¹å¾æ£€æµ‹
                gray = cv2.cvtColor(p, cv2.COLOR_BGR2GRAY)
                mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)[1]

                # ç‰¹å¾1: ç¨€ç–åº¦ï¼ˆé“¾æ¡å æ¯”å°ï¼‰
                total_pixels = h * w
                mask_pixels = np.sum(mask > 0)
                area_ratio = mask_pixels / total_pixels

                # ç‰¹å¾2: è¾¹ç¼˜å»¶ä¼¸ï¼ˆå¼€æ”¾å¼é“¾æ¡ä¼šå»¶ä¼¸åˆ°è¾¹ç¼˜ï¼‰
                h_margin = max(1, int(h * 0.05))
                w_margin = max(1, int(w * 0.05))
                edge_mask_pixels = (
                    np.sum(mask[0:h_margin, :] > 0) +
                    np.sum(mask[-h_margin:, :] > 0) +
                    np.sum(mask[:, 0:w_margin] > 0) +
                    np.sum(mask[:, -w_margin:] > 0)
                )
                edge_touch_ratio = edge_mask_pixels / mask_pixels if mask_pixels > 0 else 0

                # ğŸ”§ é“¾æ¡åˆ¤å®šï¼ˆç®€åŒ–ç‰ˆï¼‰
                is_chain = False

                # ğŸ¯ ç®€åŒ–åˆ¤å®šé€»è¾‘ï¼ˆåŸºäºå®é™…æµ‹è¯•ï¼‰
                # æ ¸å¿ƒå‘ç°ï¼š
                # - é—­åˆæ‰‹é•¯ï¼šåœ†åº¦ > 0.6
                # - å¼€æ”¾é¡¹é“¾/æ‰‹é“¾ï¼šåœ†åº¦ < 0.5ï¼Œä¸”ç¨€ç–ï¼ˆ< 0.2ï¼‰
                #
                # æµ‹è¯•æ•°æ®ï¼š
                # - äº§å“1: åœ†åº¦0.187, ç¨€ç–0.130 â†’ åº”è¯¥æ˜¯é“¾æ¡
                # - äº§å“2: åœ†åº¦0.319, ç¨€ç–0.140 â†’ åº”è¯¥æ˜¯é“¾æ¡
                # - äº§å“3: åœ†åº¦0.377, ç¨€ç–0.153 â†’ åº”è¯¥æ˜¯é“¾æ¡

                # ğŸ”§ æ–°åˆ¤å®šæ ‡å‡†ï¼ˆæ›´å®½æ¾ï¼‰ï¼š
                # åœ†åº¦ < 0.5 AND ç¨€ç–åº¦ < 0.2
                if circularity < 0.5 and area_ratio < 0.2:
                    is_chain = True
                    chain_products.append({
                        'index': idx,
                        'circularity': circularity,
                        'area_ratio': area_ratio,
                        'edge_touch_ratio': edge_touch_ratio
                    })

                    print(f"   ğŸ”— äº§å“{idx+1}: æ£€æµ‹åˆ°å¼€æ”¾é“¾æ¡")
                    print(f"      åœ†åº¦: {circularity:.3f}, ç¨€ç–åº¦: {area_ratio:.3f}, è¾¹ç¼˜å»¶ä¼¸: {edge_touch_ratio:.3f}")
                else:
                    print(f"   â„¹ï¸ äº§å“{idx+1}: éé“¾æ¡ (åœ†åº¦: {circularity:.3f}, ç¨€ç–åº¦: {area_ratio:.3f}, è¾¹ç¼˜: {edge_touch_ratio:.3f})")

            # å¦‚æœæ£€æµ‹åˆ°é“¾æ¡ï¼Œé€‰æ‹©åœ†åº¦æœ€ä½çš„ä½œä¸ºä¸»å›¾
            if len(chain_products) > 0:
                print(f"\n   ğŸ“ æ£€æµ‹åˆ° {len(chain_products)} ä¸ªé“¾æ¡äº§å“")

                if len(chain_products) == 1:
                    # åªæœ‰1ä¸ªé“¾æ¡ï¼Œç›´æ¥ä½¿ç”¨adaptive_focus
                    print(f"   â¡ï¸  ä½¿ç”¨ adaptive_focus å¸ƒå±€")
                    return "adaptive_focus"
                else:
                    # æœ‰å¤šä¸ªé“¾æ¡ï¼ŒæŒ‰åœ†åº¦æ’åºï¼Œé€‰æ‹©åœ†åº¦æœ€ä½çš„ä½œä¸ºä¸»å›¾
                    chain_products.sort(key=lambda x: x['circularity'])

                    main_chain = chain_products[0]
                    self.forced_main_product_index = main_chain['index']
                    print(f"   ğŸ¯ é€‰æ‹©äº§å“{main_chain['index']+1}ä½œä¸ºä¸»å›¾ (åœ†åº¦æœ€ä½: {main_chain['circularity']:.2f})")

                    for i, chain in enumerate(chain_products):
                        mark = "ğŸ‘‘ä¸»å›¾" if i == 0 else "å‰¯å›¾"
                        print(f"      {mark} äº§å“{chain['index']+1}: åœ†åº¦={chain['circularity']:.3f}")

                    return "adaptive_focus"
            else:
                # æ²¡æœ‰æ£€æµ‹åˆ°é“¾æ¡ï¼Œä½¿ç”¨æ¨ªæ’å¸ƒå±€
                print(f"   â¡ï¸  æœªæ£€æµ‹åˆ°é“¾æ¡ï¼Œä½¿ç”¨ horizontal å¸ƒå±€")
                return "horizontal"

        # é»˜è®¤ï¼š3ä¸ªäº§å“ä¸”æ— æ³•åˆ¤æ–­æ—¶ï¼Œä½¿ç”¨æ¨ªæ’
        return "horizontal"

    def preprocess_label(self, text: str) -> str:
        """é¢„å¤„ç†æ ‡ç­¾æ–‡æœ¬ï¼šç»Ÿä¸€å…¨è§’å­—ç¬¦"""
        if not text:
            return ""

        # æ›¿æ¢å¸¸è§çš„åŠè§’ç¬¦å·ä¸ºå…¨è§’
        replacements = {
            'x': 'Ã—',  # åŠè§’xæ›¿æ¢ä¸ºä¹˜å·
            'X': 'Ã—',  # å¤§å†™Xä¹Ÿæ›¿æ¢
            '*': 'Ã—',  # æ˜Ÿå·æ›¿æ¢ä¸ºä¹˜å·
        }

        result = text
        for half, full in replacements.items():
            result = result.replace(half, full)

        return result

    def get_available_font(self, size: int):
        """è·å–å¯ç”¨å­—ä½“ï¼Œæ”¯æŒä¸­æ–‡"""
        # å¸¸è§ç³»ç»Ÿå­—ä½“è·¯å¾„
        font_paths = [
            # Windows
            "C:/Windows/Fonts/simhei.ttf",
            "C:/Windows/Fonts/msyh.ttc",
            "C:/Windows/Fonts/arial.ttf",
            # macOS
            "/System/Library/Fonts/PingFang.ttc",
            "/System/Library/Fonts/Arial.ttf",
            # Linux
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/wqy-microhei.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"
        ]

        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    return ImageFont.truetype(font_path, size)
                except:
                    continue

        # ä½¿ç”¨é»˜è®¤å­—ä½“
        try:
            return ImageFont.load_default()
        except:
            return ImageFont.load_default()

    def calculate_label_height(self, label: str, font_size: int, product_width: int) -> Tuple[int, int]:
        """
        è®¡ç®—æ ‡ç­¾åŒºåŸŸé«˜åº¦

        è¿”å›: (text_h, label_area_height)
        """
        # åˆ›å»ºä¸´æ—¶PILå›¾åƒç”¨äºè®¡ç®—æ–‡å­—å°ºå¯¸
        temp_img = Image.new('RGB', (100, 100), (255, 255, 255))
        draw = ImageDraw.Draw(temp_img)

        # è·å–å­—ä½“
        font = self.get_available_font(font_size)

        # è®¡ç®—æ–‡å­—å°ºå¯¸
        bbox = draw.textbbox((0, 0), label, font=font)
        text_w = bbox[2] - bbox[0]
        text_h = bbox[3] - bbox[1]

        # å¦‚æœæ–‡å­—å¤ªå®½ï¼Œéœ€è¦ç¼©æ”¾å­—ä½“
        if text_w > product_width * 0.8:
            scale = (product_width * 0.8) / text_w
            new_font_size = max(20, int(font_size * scale))
            font = self.get_available_font(new_font_size)
            bbox = draw.textbbox((0, 0), label, font=font)
            text_h = bbox[3] - bbox[1]

        # è®¡ç®—æ ‡ç­¾åŒºåŸŸé«˜åº¦
        extra_padding = max(40, int(text_h * 0.5))
        label_area_height = text_h + extra_padding

        return text_h, label_area_height

    def add_label(self, product: np.ndarray, label: str, position: str, font_size: int, margin: int,
                  unified_label_height: int = None) -> np.ndarray:
        """
        ä¸ºäº§å“æ·»åŠ æ ‡ç­¾

        å‚æ•°:
            unified_label_height: ç»Ÿä¸€çš„æ ‡ç­¾åŒºåŸŸé«˜åº¦ï¼ˆç”¨äºå¯¹é½åŒä¸€ç»„çš„æ‰€æœ‰äº§å“ï¼‰
        """
        if not label or position == "none":
            return product

        h, w = product.shape[:2]

        # è½¬æ¢ä¸ºPILå¤„ç†æ–‡å­—
        pil_img = Image.fromarray(cv2.cvtColor(product, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)

        # è·å–å­—ä½“
        font = self.get_available_font(font_size)

        # è®¡ç®—æ–‡å­—å°ºå¯¸
        bbox = draw.textbbox((0, 0), label, font=font)
        text_w = bbox[2] - bbox[0]
        text_h = bbox[3] - bbox[1]

        # ğŸ”§ ä¿®å¤2: æ›´æ™ºèƒ½çš„å­—ä½“å¤§å°è°ƒæ•´ï¼ŒåŸºäºäº§å“å®é™…å°ºå¯¸
        if text_w > w * 0.8:
            scale = (w * 0.8) / text_w
            new_font_size = max(20, int(font_size * scale))
            font = self.get_available_font(new_font_size)
            bbox = draw.textbbox((0, 0), label, font=font)
            text_w = bbox[2] - bbox[0]
            text_h = bbox[3] - bbox[1]

        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ‡ç­¾åŒºåŸŸé«˜åº¦ï¼ˆå¦‚æœæä¾›ï¼‰
        if unified_label_height is not None:
            label_area_height = unified_label_height
        else:
            # å¦åˆ™è®¡ç®—ç‹¬ç«‹çš„æ ‡ç­¾é«˜åº¦
            extra_padding = max(40, int(text_h * 0.5))
            label_area_height = text_h + extra_padding

        # åˆ›å»ºæ–°ç”»å¸ƒ
        if position == "bottom":
            new_h = h + label_area_height + margin
            new_img = Image.new('RGB', (w, new_h), (255, 255, 255))
            new_img.paste(pil_img, (0, 0))
            text_x = (w - text_w) // 2
            # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿æ–‡å­—åœ¨æ ‡ç­¾åŒºåŸŸä¸­å‚ç›´å±…ä¸­ï¼Œæœ‰è¶³å¤Ÿçš„ä¸Šä¸‹ç©ºé—´
            text_y = h + margin + (label_area_height - text_h) // 2
        else:  # top
            new_h = h + label_area_height + margin
            new_img = Image.new('RGB', (w, new_h), (255, 255, 255))
            new_img.paste(pil_img, (0, label_area_height + margin))
            text_x = (w - text_w) // 2
            # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿æ–‡å­—åœ¨æ ‡ç­¾åŒºåŸŸä¸­å‚ç›´å±…ä¸­ï¼Œæœ‰è¶³å¤Ÿçš„ä¸Šä¸‹ç©ºé—´
            text_y = (label_area_height - text_h) // 2

        # ç»˜åˆ¶æ–‡å­—
        draw = ImageDraw.Draw(new_img)
        draw.text((text_x, text_y), label, font=font, fill=(0, 0, 0))

        # è½¬æ¢å›OpenCV
        return cv2.cvtColor(np.array(new_img), cv2.COLOR_RGB2BGR)

    def create_collage(self, products: List[np.ndarray], layout: str, output_width: int,
                      output_height: int, spacing: int, padding: int, scale_factor: float,
                      adaptive_direction: str = "auto", min_spacing: int = 10) -> np.ndarray:
        """åˆ›å»ºæ‹¼æ¥å›¾"""
        if not products:
            return np.ones((output_height, output_width, 3), dtype=np.uint8) * 255

        if layout == "single":
            return self.create_single_layout(products[0], output_width, output_height, padding, scale_factor)
        elif layout == "horizontal":
            return self.create_horizontal_layout(products, output_width, output_height, spacing, padding, scale_factor, min_spacing)
        elif layout == "vertical":
            return self.create_vertical_layout(products, output_width, output_height, spacing, padding, scale_factor)
        elif layout == "grid":
            return self.create_grid_layout(products, output_width, output_height, spacing, padding, scale_factor)
        elif layout == "adaptive_focus":
            return self.create_adaptive_focus_layout(products, output_width, output_height, spacing, padding, scale_factor, adaptive_direction)
        else:
            return self.create_grid_layout(products, output_width, output_height, spacing, padding, scale_factor)

    def create_single_layout(self, product: np.ndarray, canvas_w: int, canvas_h: int,
                           padding: int, scale_factor: float) -> np.ndarray:
        """å•ä¸ªäº§å“å±…ä¸­å¸ƒå±€"""
        h, w = product.shape[:2]

        # è®¡ç®—å¯ç”¨ç©ºé—´
        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_x = available_w / w
        scale_y = available_h / h
        scale = min(scale_x, scale_y) * scale_factor

        # ç¼©æ”¾å›¾ç‰‡
        new_w = max(1, int(w * scale))
        new_h = max(1, int(h * scale))
        resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)

        # åˆ›å»ºç”»å¸ƒå¹¶å±…ä¸­æ”¾ç½®
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
        x = (canvas_w - new_w) // 2
        y = (canvas_h - new_h) // 2

        if 0 <= x < canvas_w - new_w and 0 <= y < canvas_h - new_h:
            canvas[y:y+new_h, x:x+new_w] = resized

        return canvas

    def create_horizontal_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                               spacing: int, padding: int, scale_factor: float, min_spacing: int = 10) -> np.ndarray:
        """æ°´å¹³å¸ƒå±€"""
        # è®¡ç®—æ€»å®½åº¦å’Œæœ€å¤§é«˜åº¦
        total_w = sum([p.shape[1] for p in products])
        max_h = max([p.shape[0] for p in products])

        # ğŸ”§ ä¿®å¤1: å‡å°‘é—´è·ï¼Œä½¿ç”¨å¯è°ƒèŠ‚çš„æœ€å°é—´è·å‚æ•°
        actual_spacing = max(spacing, min_spacing)  # ä½¿ç”¨å¯è°ƒèŠ‚çš„æœ€å°é—´è·ï¼Œæ›´ç´§å‡‘

        # è®¡ç®—å¯ç”¨ç©ºé—´
        available_w = canvas_w - 2 * padding - actual_spacing * (len(products) - 1)
        available_h = canvas_h - 2 * padding

        # è®¡ç®—ç»Ÿä¸€ç¼©æ”¾æ¯”ä¾‹
        scale_x = available_w / total_w
        scale_y = available_h / max_h
        scale = min(scale_x, scale_y) * scale_factor

        # ç¼©æ”¾æ‰€æœ‰äº§å“
        resized_products = []
        for product in products:
            h, w = product.shape[:2]
            new_w = max(1, int(w * scale))
            new_h = max(1, int(h * scale))
            resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            resized_products.append(resized)

        # è®¡ç®—å®é™…ä½¿ç”¨çš„æ€»å®½åº¦
        actual_w = sum([p.shape[1] for p in resized_products]) + actual_spacing * (len(products) - 1)
        max_resized_h = max([p.shape[0] for p in resized_products])

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # å±…ä¸­èµ·å§‹ä½ç½®
        start_x = (canvas_w - actual_w) // 2
        start_y = (canvas_h - max_resized_h) // 2

        # ä¾æ¬¡æ”¾ç½®äº§å“
        current_x = start_x
        for product in resized_products:
            h, w = product.shape[:2]
            y = start_y + (max_resized_h - h) // 2  # å‚ç›´å±…ä¸­

            if 0 <= y < canvas_h - h and 0 <= current_x < canvas_w - w:
                canvas[y:y+h, current_x:current_x+w] = product

            current_x += w + actual_spacing

        return canvas

    def create_vertical_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                             spacing: int, padding: int, scale_factor: float) -> np.ndarray:
        """å‚ç›´å¸ƒå±€"""
        total_h = sum([p.shape[0] for p in products])
        max_w = max([p.shape[1] for p in products])

        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding - spacing * (len(products) - 1)

        scale_x = available_w / max_w
        scale_y = available_h / total_h
        scale = min(scale_x, scale_y) * scale_factor

        resized_products = []
        for product in products:
            h, w = product.shape[:2]
            new_w = max(1, int(w * scale))
            new_h = max(1, int(h * scale))
            resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            resized_products.append(resized)

        actual_h = sum([p.shape[0] for p in resized_products]) + spacing * (len(products) - 1)
        max_resized_w = max([p.shape[1] for p in resized_products])

        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        start_x = (canvas_w - max_resized_w) // 2
        start_y = (canvas_h - actual_h) // 2

        current_y = start_y
        for product in resized_products:
            h, w = product.shape[:2]
            x = start_x + (max_resized_w - w) // 2

            if 0 <= x < canvas_w - w and 0 <= current_y < canvas_h - h:
                canvas[current_y:current_y+h, x:x+w] = product

            current_y += h + spacing

        return canvas

    def create_grid_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                          spacing: int, padding: int, scale_factor: float) -> np.ndarray:
        """ç½‘æ ¼å¸ƒå±€"""
        n = len(products)
        if n <= 1:
            return self.create_single_layout(products[0], canvas_w, canvas_h, padding, scale_factor)
        elif n == 2:
            return self.create_horizontal_layout(products, canvas_w, canvas_h, spacing, padding, scale_factor)
        elif n == 3:
            # 2+1å¸ƒå±€
            rows, cols = 2, 2
        elif n == 4:
            rows, cols = 2, 2
        elif n <= 6:
            rows, cols = 2, 3
        elif n <= 9:
            rows, cols = 3, 3
        else:
            # è¶…è¿‡9ä¸ªï¼Œå–å‰9ä¸ª
            products = products[:9]
            rows, cols = 3, 3

        # è®¡ç®—æ¯ä¸ªæ ¼å­çš„å¤§å°
        available_w = canvas_w - 2 * padding - spacing * (cols - 1)
        available_h = canvas_h - 2 * padding - spacing * (rows - 1)
        cell_w = available_w // cols
        cell_h = available_h // rows

        # è®¡ç®—äº§å“çš„ç»Ÿä¸€ç¼©æ”¾æ¯”ä¾‹
        max_product_w = max([p.shape[1] for p in products])
        max_product_h = max([p.shape[0] for p in products])

        scale_x = cell_w / max_product_w
        scale_y = cell_h / max_product_h
        scale = min(scale_x, scale_y) * scale_factor

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # æ”¾ç½®äº§å“
        for i, product in enumerate(products):
            row = i // cols
            col = i % cols

            # ç¼©æ”¾äº§å“
            h, w = product.shape[:2]
            new_w = max(1, int(w * scale))
            new_h = max(1, int(h * scale))
            resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)

            # è®¡ç®—ä½ç½®ï¼ˆåœ¨æ ¼å­å†…å±…ä¸­ï¼‰
            cell_x = padding + col * (cell_w + spacing)
            cell_y = padding + row * (cell_h + spacing)

            x = cell_x + (cell_w - new_w) // 2
            y = cell_y + (cell_h - new_h) // 2

            if 0 <= x < canvas_w - new_w and 0 <= y < canvas_h - new_h:
                canvas[y:y+new_h, x:x+new_w] = resized

        return canvas

    def create_adaptive_focus_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                                   spacing: int, padding: int, scale_factor: float, adaptive_direction: str = "auto") -> np.ndarray:
        """
        ğŸ”§ æ™ºèƒ½ä¸»æ¬¡å¸ƒå±€ - å¢å¼ºé“¾æ¡è¯†åˆ«ï¼ˆæ¥è‡ªaaa.pyï¼‰

        Args:
            direction: ä¸»äº§å“æ”¾ç½®æ–¹å‘ (auto/left/right/top/bottom)
        """
        if len(products) < 2:
            return self.create_single_layout(products[0], canvas_w, canvas_h, padding, scale_factor)

        # ğŸ†• å¦‚æœæœ‰å¼ºåˆ¶æŒ‡å®šçš„ä¸»äº§å“ç´¢å¼•ï¼Œç›´æ¥ä½¿ç”¨
        if self.forced_main_product_index is not None and 0 <= self.forced_main_product_index < len(products):
            max_idx = self.forced_main_product_index
            print(f"   ğŸ¯ ä½¿ç”¨å¼ºåˆ¶æŒ‡å®šçš„ä¸»äº§å“: äº§å“{max_idx+1}")

            # ä½¿ç”¨å®Œåé‡ç½®
            self.forced_main_product_index = None

            main_product = products[max_idx]
            other_products = [p for i, p in enumerate(products) if i != max_idx]

            # å¼ºåˆ¶æ”¾ç½®åœ¨ä¸Šæ–¹
            adaptive_direction = "top"

        else:
            # ğŸ”§ æ™ºèƒ½åˆ¤æ–­ä¸»äº§å“ - å¢å¼ºç‰ˆ
            product_features = []
            for i, p in enumerate(products):
                h, w = p.shape[:2]
                area = h * w
                aspect_ratio = w / h  # å®½é«˜æ¯”

                # ğŸ”§ å¢å¼ºé“¾æ¡æ£€æµ‹
                is_necklace = False
                necklace_score = 0

                # ç‰¹å¾1: æç«¯å®½é«˜æ¯”ï¼ˆæ›´å®½æ¾çš„é˜ˆå€¼ï¼‰
                if aspect_ratio > 1.3 or aspect_ratio < 0.77:  # ä»1.5/0.67æ”¹ä¸º1.3/0.77
                    necklace_score += 30

                # ç‰¹å¾2: è¾¹ç¼˜å»¶ä¼¸æ£€æµ‹ï¼ˆå¢å¼ºå¼€æ”¾å¼é“¾æ¡æ£€æµ‹ï¼‰
                gray = cv2.cvtColor(p, cv2.COLOR_BGR2GRAY)
                edges = cv2.Canny(gray, 30, 100)

                h_margin = max(1, int(h * 0.05))
                w_margin = max(1, int(w * 0.05))

                # æ£€æµ‹å››ä¸ªè¾¹ç¼˜åŒºåŸŸçš„è¾¹ç¼˜å¯†åº¦
                top_density = np.sum(edges[0:h_margin, :]) / (h_margin * w)
                bottom_density = np.sum(edges[-h_margin:, :]) / (h_margin * w)
                left_density = np.sum(edges[:, 0:w_margin]) / (h * w_margin)
                right_density = np.sum(edges[:, -w_margin:]) / (h * w_margin)

                # ğŸ”§ å¢å¼ºå¼€æ”¾å¼æ£€æµ‹ï¼šæ£€æµ‹äº§å“ä¸»ä½“æ˜¯å¦æ¥è§¦è¾¹ç¼˜ï¼ˆéç™½è‰²åƒç´ ï¼‰
                # å¼€æ”¾å¼é“¾æ¡çš„ç‰¹å¾æ˜¯äº§å“æœ¬èº«å»¶ä¼¸åˆ°è¾¹ç¼˜
                mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)[1]
                top_product_pixels = np.sum(mask[0:h_margin, :]) / (h_margin * w * 255)
                bottom_product_pixels = np.sum(mask[-h_margin:, :]) / (h_margin * w * 255)
                left_product_pixels = np.sum(mask[:, 0:w_margin]) / (h * w_margin * 255)
                right_product_pixels = np.sum(mask[:, -w_margin:]) / (h * w_margin * 255)

                # è¾¹ç¼˜å¯†åº¦é˜ˆå€¼
                density_threshold = 0.05
                product_threshold = 0.02  # äº§å“åƒç´ é˜ˆå€¼ï¼ˆå¼€æ”¾å¼é“¾æ¡ç‰¹å¾ï¼‰

                edge_touches = 0
                open_edges = 0  # å¼€æ”¾è¾¹ç¼˜è®¡æ•°

                if top_density > density_threshold:
                    edge_touches += 1
                    necklace_score += 25
                    if top_product_pixels > product_threshold:
                        open_edges += 1
                        necklace_score += 35  # å¼€æ”¾è¾¹ç¼˜åŠ åˆ†æ›´é«˜
                if bottom_density > density_threshold:
                    edge_touches += 1
                    necklace_score += 25
                    if bottom_product_pixels > product_threshold:
                        open_edges += 1
                        necklace_score += 35
                if left_density > density_threshold:
                    edge_touches += 1
                    necklace_score += 25
                    if left_product_pixels > product_threshold:
                        open_edges += 1
                        necklace_score += 35
                if right_density > density_threshold:
                    edge_touches += 1
                    necklace_score += 25
                    if right_product_pixels > product_threshold:
                        open_edges += 1
                        necklace_score += 35

                # ğŸ”§ å¢å¼ºåˆ¤å®šï¼šå¼€æ”¾è¾¹ç¼˜ï¼ˆäº§å“å»¶ä¼¸åˆ°è¾¹ç•Œï¼‰æ˜¯é“¾æ¡çš„å¼ºç‰¹å¾
                if open_edges >= 2:  # è‡³å°‘2ä¸ªè¾¹ç¼˜æœ‰äº§å“å»¶ä¼¸
                    is_necklace = True
                    necklace_score += 80
                elif edge_touches >= 2:  # æˆ–è‡³å°‘2ä¸ªè¾¹ç¼˜æœ‰è¾¹ç¼˜å¯†åº¦
                    is_necklace = True
                    necklace_score += 50

                # ç‰¹å¾3: ç»†é•¿åº¦ï¼ˆå‘¨é•¿/é¢ç§¯æ¯”ï¼‰
                contours, _ = cv2.findContours(
                    cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)[1],
                    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
                )
                if contours:
                    largest_contour = max(contours, key=cv2.contourArea)
                    perimeter = cv2.arcLength(largest_contour, True)
                    if area > 0:
                        slenderness = perimeter * perimeter / area
                        if slenderness > 50:  # ç»†é•¿åº¦é«˜
                            necklace_score += 30
                            is_necklace = True

                product_features.append({
                    'index': i,
                    'area': area,
                    'aspect_ratio': aspect_ratio,
                    'is_necklace': is_necklace,
                    'necklace_score': necklace_score,
                    'edge_touches': edge_touches,
                    'score': 0
                })

            # è®¡ç®—ç»¼åˆå¾—åˆ†
            max_area = max([f['area'] for f in product_features])
            for feature in product_features:
                score = 0

                # é¢ç§¯å¾—åˆ†ï¼ˆæƒé‡é™ä½ï¼‰
                score += (feature['area'] / max_area) * 30

                # é“¾æ¡å¾—åˆ†ï¼ˆæƒé‡æé«˜ï¼‰
                score += feature['necklace_score']

                feature['score'] = score

            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ä½œä¸ºä¸»äº§å“
            product_features.sort(key=lambda x: x['score'], reverse=True)
            max_idx = product_features[0]['index']

            # è°ƒè¯•ä¿¡æ¯
            print(f"   ğŸ” ä¸»äº§å“è¯†åˆ«:")
            for i, f in enumerate(product_features):
                mark = "ğŸ‘‘ä¸»" if i == 0 else "  "
                print(f"      {mark} äº§å“{f['index']+1}: å¾—åˆ†{f['score']:.1f} "
                      f"(é“¾æ¡:{f['is_necklace']}, è¾¹ç¼˜:{f['edge_touches']}, "
                      f"å®½é«˜æ¯”:{f['aspect_ratio']:.2f})")

            main_product = products[max_idx]
            other_products = [p for i, p in enumerate(products) if i != max_idx]

            # ğŸ”§ å¼ºåˆ¶è§„åˆ™ï¼šé“¾æ¡/å¼€æ”¾å¼§å½¢ç±»äº§å“å¿…é¡»æ”¾ä¸Šæ–¹
            if adaptive_direction == "auto":
                if product_features[0]['is_necklace']:
                    adaptive_direction = "top"
                    print(f"   ğŸ“ æ£€æµ‹åˆ°é“¾æ¡/å¼€æ”¾å¼§å½¢äº§å“ï¼Œå¼ºåˆ¶æ”¾ç½®ä¸Šæ–¹")
                elif canvas_w > canvas_h * 1.2:
                    adaptive_direction = "left" if len(other_products) <= 2 else "top"
                elif canvas_h > canvas_w * 1.2:
                    adaptive_direction = "top" if len(other_products) <= 2 else "left"
                else:
                    adaptive_direction = "left" if len(other_products) <= 3 else "top"

            # ğŸ”§ å³ä½¿ç”¨æˆ·æŒ‡å®šäº†æ–¹å‘ï¼Œå¦‚æœæ£€æµ‹åˆ°é“¾æ¡ä¹Ÿå¼ºåˆ¶æ”¹ä¸ºtop
            if product_features[0]['is_necklace'] and adaptive_direction != "top":
                print(f"   âš ï¸  æ£€æµ‹åˆ°é“¾æ¡äº§å“ï¼Œè¦†ç›–ç”¨æˆ·è®¾ç½®ï¼Œå¼ºåˆ¶æ”¾ç½®ä¸Šæ–¹")
                adaptive_direction = "top"

        # æ ¹æ®æ–¹å‘é€‰æ‹©å¸ƒå±€å‡½æ•°
        if adaptive_direction == "left":
            return self.create_adaptive_horizontal_split(main_product, other_products, canvas_w, canvas_h,
                                                  spacing, padding, scale_factor, main_on_left=True)
        elif adaptive_direction == "right":
            return self.create_adaptive_horizontal_split(main_product, other_products, canvas_w, canvas_h,
                                                  spacing, padding, scale_factor, main_on_left=False)
        elif adaptive_direction == "top":
            return self.create_adaptive_vertical_split(main_product, other_products, canvas_w, canvas_h,
                                                spacing, padding, scale_factor, main_on_top=True)
        elif adaptive_direction == "bottom":
            return self.create_adaptive_vertical_split(main_product, other_products, canvas_w, canvas_h,
                                                spacing, padding, scale_factor, main_on_top=False)
        else:
            return self.create_adaptive_horizontal_split(main_product, other_products, canvas_w, canvas_h,
                                                  spacing, padding, scale_factor, main_on_left=True)

    def create_adaptive_horizontal_split(self, main_product: np.ndarray, other_products: List[np.ndarray],
                                   canvas_w: int, canvas_h: int, spacing: int,
                                   padding: int, scale_factor: float, main_on_left: bool = True) -> np.ndarray:
        """
        å·¦å³åˆ†å‰²å¸ƒå±€ï¼ˆæ¥è‡ªaaa.pyï¼‰
        Args:
            main_on_left: True=ä¸»äº§å“åœ¨å·¦ï¼ŒFalse=ä¸»äº§å“åœ¨å³
        """
        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding

        # ä¸»äº§å“å 45%å®½åº¦
        main_w = int(available_w * 0.45)
        other_w = available_w - main_w - spacing

        # ç¼©æ”¾ä¸»äº§å“
        mh, mw = main_product.shape[:2]
        main_scale = min(main_w / mw, available_h / mh) * scale_factor
        main_new_w = max(1, int(mw * main_scale))
        main_new_h = max(1, int(mh * main_scale))
        main_resized = cv2.resize(main_product, (main_new_w, main_new_h), interpolation=cv2.INTER_LANCZOS4)

        # ç¼©æ”¾å…¶ä»–äº§å“ï¼ˆç«–æ’ï¼‰
        num_others = len(other_products)
        other_spacing = spacing * (num_others - 1)

        max_original_w = max([p.shape[1] for p in other_products])
        total_original_h = sum([p.shape[0] for p in other_products])

        scale_by_width = other_w / max_original_w
        scale_by_height = (available_h - other_spacing) / total_original_h
        unified_scale = min(scale_by_width, scale_by_height) * scale_factor

        others_resized = []
        for p in other_products:
            h, w = p.shape[:2]
            new_w = max(1, int(w * unified_scale))
            new_h = max(1, int(h * unified_scale))
            others_resized.append(cv2.resize(p, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4))

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # å†³å®šä½ç½®
        if main_on_left:
            # ä¸»äº§å“åœ¨å·¦
            main_x = padding
            others_start_x = padding + main_w + spacing
        else:
            # ä¸»äº§å“åœ¨å³
            main_x = padding + other_w + spacing
            others_start_x = padding

        # æ”¾ç½®ä¸»äº§å“ï¼ˆå±…ä¸­ï¼‰
        main_y = (canvas_h - main_new_h) // 2
        if 0 <= main_x < canvas_w - main_new_w and 0 <= main_y < canvas_h - main_new_h:
            canvas[main_y:main_y+main_new_h, main_x:main_x+main_new_w] = main_resized

        # æ”¾ç½®å…¶ä»–äº§å“ï¼ˆç«–æ’å±…ä¸­ï¼‰
        total_other_h = sum([img.shape[0] for img in others_resized]) + other_spacing
        max_other_w = max([img.shape[1] for img in others_resized])

        start_y = (canvas_h - total_other_h) // 2
        start_x = others_start_x + (other_w - max_other_w) // 2

        current_y = start_y
        for img in others_resized:
            h, w = img.shape[:2]
            x = start_x + (max_other_w - w) // 2
            if 0 <= x < canvas_w - w and 0 <= current_y < canvas_h - h:
                canvas[current_y:current_y+h, x:x+w] = img
            current_y += h + spacing

        return canvas

    def create_adaptive_vertical_split(self, main_product: np.ndarray, other_products: List[np.ndarray],
                                canvas_w: int, canvas_h: int, spacing: int,
                                padding: int, scale_factor: float, main_on_top: bool = True) -> np.ndarray:
        """
        ä¸Šä¸‹åˆ†å‰²å¸ƒå±€ï¼ˆæ¥è‡ªaaa.pyï¼‰
        Args:
            main_on_top: True=ä¸»äº§å“åœ¨ä¸Šï¼ŒFalse=ä¸»äº§å“åœ¨ä¸‹
        """
        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding

        # ä¸»äº§å“å 45%é«˜åº¦
        main_h = int(available_h * 0.45)
        other_h = available_h - main_h - spacing

        # ç¼©æ”¾ä¸»äº§å“
        mh, mw = main_product.shape[:2]
        main_scale = min(available_w / mw, main_h / mh) * scale_factor
        main_new_w = max(1, int(mw * main_scale))
        main_new_h = max(1, int(mh * main_scale))
        main_resized = cv2.resize(main_product, (main_new_w, main_new_h), interpolation=cv2.INTER_LANCZOS4)

        # ç¼©æ”¾å…¶ä»–äº§å“ï¼ˆæ¨ªæ’ï¼‰
        num_others = len(other_products)
        other_spacing = spacing * (num_others - 1)

        total_original_w = sum([p.shape[1] for p in other_products])
        max_original_h = max([p.shape[0] for p in other_products])

        scale_by_width = (available_w - other_spacing) / total_original_w
        scale_by_height = other_h / max_original_h
        unified_scale = min(scale_by_width, scale_by_height) * scale_factor

        others_resized = []
        for p in other_products:
            h, w = p.shape[:2]
            new_w = max(1, int(w * unified_scale))
            new_h = max(1, int(h * unified_scale))
            others_resized.append(cv2.resize(p, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4))

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # å†³å®šä½ç½®
        if main_on_top:
            # ä¸»äº§å“åœ¨ä¸Š
            main_y = padding
            others_start_y = padding + main_h + spacing
        else:
            # ä¸»äº§å“åœ¨ä¸‹
            main_y = padding + other_h + spacing
            others_start_y = padding

        # æ”¾ç½®ä¸»äº§å“ï¼ˆå±…ä¸­ï¼‰
        main_x = (canvas_w - main_new_w) // 2
        if 0 <= main_x < canvas_w - main_new_w and 0 <= main_y < canvas_h - main_new_h:
            canvas[main_y:main_y+main_new_h, main_x:main_x+main_new_w] = main_resized

        # æ”¾ç½®å…¶ä»–äº§å“ï¼ˆæ¨ªæ’å±…ä¸­ï¼‰
        total_other_w = sum([img.shape[1] for img in others_resized]) + other_spacing
        max_other_h = max([img.shape[0] for img in others_resized])

        start_x = (canvas_w - total_other_w) // 2
        start_y = others_start_y + (other_h - max_other_h) // 2

        current_x = start_x
        for img in others_resized:
            h, w = img.shape[:2]
            y = start_y + (max_other_h - h) // 2
            if 0 <= y < canvas_h - h and 0 <= current_x < canvas_w - w:
                canvas[y:y+h, current_x:current_x+w] = img
            current_x += w + spacing

        return canvas

    def batch_collage(self, images, images_per_collage, layout, output_width, output_height,
                     spacing, min_spacing, outer_padding, product_scale, crop_margin,
                     skip_empty=True, labels="", label_font_size=180,
                     label_position="bottom", label_margin=40, hide_pcs_one=False, adaptive_direction="auto"):
        """
        æ‰¹é‡æ‹¼æ¥ä¸»å‡½æ•° - å†…éƒ¨æŠ å›¾ç‰ˆ

        ğŸ†• ä¿®æ”¹: ä½¿ç”¨å†…éƒ¨æŠ å›¾ï¼Œä¿ç•™ä¸»ä½“å’Œé˜´å½±

        å‚æ•°:
            images: è¾“å…¥çš„å›¾ç‰‡batch [N, H, W, C]
            images_per_collage: æ¯å¼ æ‹¼æ¥å›¾åŒ…å«å¤šå°‘å¼ åŸå›¾
            labels: æ ‡ç­¾æ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ªæ ‡ç­¾
            label_font_size: æ ‡ç­¾å­—ä½“å¤§å°
            label_position: æ ‡ç­¾ä½ç½® (bottom/top/none)
            label_margin: æ ‡ç­¾ä¸äº§å“çš„é—´è·
            hide_pcs_one: å½“æ ‡ç­¾ä¸º"Ã—1"æˆ–"x1"æ—¶éšè—æ ‡ç­¾
            adaptive_direction: adaptive_focuså¸ƒå±€çš„ä¸»äº§å“æ–¹å‘
            å…¶ä»–å‚æ•°: æ‹¼æ¥è®¾ç½®

        è¿”å›:
            æ‹¼æ¥åçš„å›¾ç‰‡batch
        """

        batch_size = images.shape[0]

        total_groups = math.ceil(batch_size / images_per_collage)

        # è§£ææ ‡ç­¾ - æ”¯æŒé€—å·å’Œæ¢è¡Œä¸¤ç§åˆ†éš”æ–¹å¼
        label_list = []
        if labels and labels.strip():
            labels_text = self.preprocess_label(labels.strip())

            # æ£€æµ‹åˆ†éš”ç¬¦ç±»å‹
            if ',' in labels_text:
                # é€—å·åˆ†éš”æ¨¡å¼
                label_list = [self.preprocess_label(label.strip()) for label in labels_text.split(',') if label.strip()]
                print(f"   ğŸ“ æ ‡ç­¾æ•°é‡: {len(label_list)}ä¸ª (é€—å·åˆ†éš”)")
            else:
                # æ¢è¡Œåˆ†éš”æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
                label_list = [self.preprocess_label(line.strip()) for line in labels_text.split('\n') if line.strip()]
                print(f"   ğŸ“ æ ‡ç­¾æ•°é‡: {len(label_list)}ä¸ª (æ¢è¡Œåˆ†éš”)")


        print("\n" + "=" * 70)
        print("ğŸ¨ æ‰¹é‡äº§å“æ‹¼æ¥èŠ‚ç‚¹ v2.0 (å†…éƒ¨æŠ å›¾ç‰ˆ - ä¿ç•™é˜´å½±)")
        print("=" * 70)
        print(f"   è¾“å…¥å›¾ç‰‡: {batch_size}å¼ ")
        print(f"   æ¯ç»„æ•°é‡: {images_per_collage}å¼ ")
        print(f"   æ‹¼æ¥ç»„æ•°: {total_groups}ç»„")
        print(f"   è¾“å‡ºå°ºå¯¸: {output_width}x{output_height}px")
        print(f"   å¸ƒå±€æ¨¡å¼: {layout}")
        if layout == "adaptive_focus":
            print(f"   ä¸»äº§å“æ–¹å‘: {adaptive_direction}")
        if label_list:
            print(f"   æ ‡ç­¾ä½ç½®: {label_position}")
            print(f"   æ ‡ç­¾å­—ä½“: {label_font_size}px")
            if hide_pcs_one:
                print(f"   éšè—PCS=1: æ˜¯")
        print("=" * 70)

        # å­˜å‚¨æ‰€æœ‰æ‹¼æ¥ç»“æœ
        collage_results = []

        # æŒ‰ç»„å¤„ç†
        for group_idx in range(total_groups):
            start_idx = group_idx * images_per_collage
            end_idx = min(start_idx + images_per_collage, batch_size)
            group_size = end_idx - start_idx

            print(f"\nğŸ“¦ å¤„ç†ç¬¬{group_idx+1}/{total_groups}ç»„ (å›¾ç‰‡{start_idx+1}-{end_idx})")

            # è·³è¿‡ä¸å®Œæ•´çš„ç»„ï¼ˆå¦‚æœè®¾ç½®äº†skip_emptyï¼‰
            if skip_empty and group_size < images_per_collage:
                print(f"   âš ï¸  è·³è¿‡ä¸å®Œæ•´ç»„ (åªæœ‰{group_size}å¼ )")
                continue

            # æå–å½“å‰ç»„çš„å›¾ç‰‡
            group_images = images[start_idx:end_idx]

            # å¤„ç†å½“å‰ç»„çš„æ¯å¼ å›¾ç‰‡
            products = []
            for i, img_tensor in enumerate(group_images):
                try:
                    # è½¬æ¢ä¸ºOpenCV
                    cv2_img = self.tensor_to_cv2(img_tensor)

                    # ğŸ†• ä½¿ç”¨å†…éƒ¨æŠ å›¾ï¼ˆä¿ç•™ä¸»ä½“å’Œé˜´å½±ï¼‰
                    product = self.remove_background_with_shadow(cv2_img, crop_margin)

                    h, w = product.shape[:2]
                    print(f"   å›¾ç‰‡{i+1}: {w}x{h}px (å·²æŠ å›¾ï¼Œä¿ç•™é˜´å½±)")

                    products.append(product)

                except Exception as e:
                    print(f"   âŒ å›¾ç‰‡{i+1}å¤„ç†å¤±è´¥: {e}")
                    continue

            if len(products) == 0:
                print(f"   âš ï¸  æœ¬ç»„æ²¡æœ‰æœ‰æ•ˆäº§å“ï¼Œè·³è¿‡")
                continue

            # é‡ç½®å¼ºåˆ¶ä¸»äº§å“ç´¢å¼•ï¼ˆæ¯ç»„ç‹¬ç«‹åˆ¤æ–­ï¼‰
            self.forced_main_product_index = None

            # å†³å®šå¸ƒå±€ï¼ˆä¼ å…¥productsç”¨äºæ™ºèƒ½åˆ¤æ–­ï¼‰
            final_layout = self.decide_layout(len(products), layout, products)
            print(f"   å¸ƒå±€: {final_layout}")

            # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šè®¡ç®—ç»Ÿä¸€çš„æ ‡ç­¾åŒºåŸŸé«˜åº¦ï¼ˆç¡®ä¿åŒä¸€ç»„æ ‡ç­¾å¯¹é½ï¼‰
            max_label_height = 0
            labels_info = []  # å­˜å‚¨æ¯ä¸ªäº§å“çš„æ ‡ç­¾ä¿¡æ¯

            for i, product in enumerate(products):
                label = ""
                current_label_position = label_position
                h, w = product.shape[:2]

                if i < len(label_list):
                    label = label_list[i]

                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥éšè—æ ‡ç­¾
                    if hide_pcs_one:
                        if re.match(r'^[Ã—x]1$|^1[ä»¶å¥—]$|^PCS:1$', label, re.IGNORECASE):
                            label = ""
                            print(f"   å›¾ç‰‡{i+1}: æ ‡ç­¾ä¸º1ï¼Œå·²éšè—")

                    # å¦‚æœæ˜¯å‚ç›´å¸ƒå±€ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯é“¾æ¡äº§å“
                    if label and final_layout == "vertical":
                        _, _, _, is_chain = self.get_product_features(product)
                        if is_chain:
                            current_label_position = "top"
                            print(f"   å›¾ç‰‡{i+1}: æ£€æµ‹åˆ°é“¾æ¡ï¼Œæ ‡ç­¾ä½ç½®æ”¹ä¸ºtop")

                labels_info.append({
                    'label': label,
                    'position': current_label_position,
                    'product_width': w
                })

                # è®¡ç®—æ ‡ç­¾é«˜åº¦
                if label and current_label_position != "none":
                    _, label_height = self.calculate_label_height(label, label_font_size, w)
                    max_label_height = max(max_label_height, label_height)

            # ğŸ”§ ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ‡ç­¾é«˜åº¦æ·»åŠ æ ‡ç­¾
            final_products = []
            for i, product in enumerate(products):
                label_info = labels_info[i]
                label = label_info['label']
                current_label_position = label_info['position']

                if label and current_label_position != "none":
                    # ä½¿ç”¨ç»Ÿä¸€çš„æ ‡ç­¾é«˜åº¦
                    product = self.add_label(product, label, current_label_position,
                                           label_font_size, label_margin, max_label_height)
                    h, w = product.shape[:2]
                    print(f"   å›¾ç‰‡{i+1}: {w}x{h}px (å«æ ‡ç­¾: '{label}', ä½ç½®: {current_label_position}, ç»Ÿä¸€é«˜åº¦: {max_label_height}px)")
                else:
                    h, w = product.shape[:2]
                    print(f"   å›¾ç‰‡{i+1}: {w}x{h}px")

                final_products.append(product)

            if len(final_products) == 0:
                print(f"   âš ï¸  æœ¬ç»„æ²¡æœ‰æœ‰æ•ˆäº§å“ï¼Œè·³è¿‡")
                continue

            # åˆ›å»ºæ‹¼æ¥å›¾
            try:
                collage = self.create_collage(final_products, final_layout, output_width, output_height,
                                            spacing, outer_padding, product_scale, adaptive_direction, min_spacing)
                
                # è½¬æ¢ä¸ºtensor
                collage_tensor = self.cv2_to_tensor(collage)
                collage_results.append(collage_tensor)
                
                print(f"   âœ… æ‹¼æ¥å®Œæˆ")
                
            except Exception as e:
                print(f"   âŒ æ‹¼æ¥å¤±è´¥: {e}")
                continue
        
        if len(collage_results) == 0:
            print(f"\nâŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ‹¼æ¥å›¾")
            # è¿”å›ç©ºç™½å›¾
            empty = np.ones((output_height, output_width, 3), dtype=np.uint8) * 255
            return (self.cv2_to_tensor(empty),)
        
        # åˆå¹¶æ‰€æœ‰æ‹¼æ¥ç»“æœ
        final_batch = torch.cat(collage_results, dim=0)
        
        print(f"\nâœ… æ‰¹é‡æ‹¼æ¥å®Œæˆ!")
        print(f"   è¾“å‡º: {final_batch.shape[0]}å¼ æ‹¼æ¥å›¾")
        print("=" * 70 + "\n")
        
        return (final_batch,)


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "SmartProductCollageBatch": SmartProductCollageBatch,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SmartProductCollageBatch": "æ™ºèƒ½äº§å“æ‹¼æ¥Â·å†…éƒ¨æŠ å›¾v2.0ğŸ¨âœ¨",
}