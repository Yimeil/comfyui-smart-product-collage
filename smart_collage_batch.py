"""
ComfyUIæ‰¹é‡äº§å“æ‹¼æ¥èŠ‚ç‚¹ - å¤–éƒ¨æŠ å›¾ç‰ˆ

åŠŸèƒ½ï¼š
- è¾“å…¥Nå¼ å›¾ç‰‡å’Œå¯¹åº”çš„masksï¼Œè‡ªåŠ¨æŒ‰æŒ‡å®šæ•°é‡åˆ†ç»„
- æ¯ç»„è‡ªåŠ¨æ‹¼æ¥æˆä¸€å¼ ç™½åº•å›¾
- æ”¯æŒæ·»åŠ ä¸­æ–‡/æ•°å­—æ ‡ç­¾ï¼ˆæ ‡ç­¾åœ¨æ¯ç»„å†…å¾ªç¯ä½¿ç”¨ï¼‰
- æ”¯æŒé€—å·åˆ†éš”æˆ–æ¢è¡Œåˆ†éš”çš„æ ‡ç­¾è¾“å…¥
- æ™ºèƒ½ä¸»æ¬¡å¸ƒå±€ï¼ˆå¤§äº§å“è‡ªåŠ¨å•ç‹¬ä¸€ä¾§ï¼‰
- è¾“å‡ºæ‰€æœ‰æ‹¼æ¥åçš„å›¾ç‰‡

å˜æ›´ï¼š
- å»æ‰å†…éƒ¨æŠ å›¾æµç¨‹ (remove_backgroundæ–¹æ³•)
- æ–°å¢masksè¾“å…¥å‚æ•°
- ç›´æ¥ä½¿ç”¨å¤–éƒ¨æä¾›çš„masksè¿›è¡ŒæŠ å›¾

ä½¿ç”¨åœºæ™¯ï¼š
- 100å¼ å›¾ + 100ä¸ªmask â†’ æ¯2å¼ æ‹¼æ¥ â†’ è¾“å‡º50å¼ æ‹¼æ¥å›¾
- 90å¼ å›¾ + 90ä¸ªmask â†’ æ¯3å¼ æ‹¼æ¥ â†’ è¾“å‡º30å¼ æ‹¼æ¥å›¾
- æ”¯æŒä¸ºæ¯ç»„ä¸­çš„äº§å“æ·»åŠ æ ‡ç­¾ï¼ˆå¦‚ï¼šç¬¬1ä¸ªäº§å“7pcsã€ç¬¬2ä¸ªäº§å“5pcsï¼‰

æ ‡ç­¾é€»è¾‘ï¼š
- æ ‡ç­¾æ•°é‡ = æ¯ç»„å›¾ç‰‡æ•°é‡ï¼ˆimages_per_collageï¼‰
- æ¯ç»„éƒ½ä½¿ç”¨ç›¸åŒçš„æ ‡ç­¾
- ä¾‹å¦‚ï¼šæ¯ç»„2å¼ ï¼Œæ ‡ç­¾ä¸º"7pcs,5pcs"æˆ–"7pcs\n5pcs"ï¼Œåˆ™æ¯ç»„çš„ç¬¬1å¼ éƒ½æ˜¯7pcsï¼Œç¬¬2å¼ éƒ½æ˜¯5pcs

æ ‡ç­¾è¾“å…¥æ ¼å¼ï¼š
- é€—å·åˆ†éš”ï¼š7pcs,5pcs,3pcs ï¼ˆé€‚åˆç¨‹åºåŒ–ç”Ÿæˆï¼‰
- æ¢è¡Œåˆ†éš”ï¼š7pcs\n5pcs\n3pcs ï¼ˆé€‚åˆæ‰‹åŠ¨è¾“å…¥ï¼‰

ç‰ˆæœ¬: 1.8 (å¤–éƒ¨æŠ å›¾ç‰ˆ - ä¿®å¤ç‰ˆ)
æ—¥æœŸ: 2025-01-27
æ›´æ–°: 
1. å»æ‰å†…éƒ¨æŠ å›¾æµç¨‹ (remove_backgroundæ–¹æ³•)
2. æ–°å¢masksè¾“å…¥å‚æ•°
3. ä¿®æ”¹extract_productæ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨å¤–éƒ¨masks
4. ä¿®å¤é—´è·ã€æ ‡ç­¾ã€é“¾æ¡è¯†åˆ«å’Œå¸ƒå±€é—®é¢˜
5. ä¿æŒå…¶ä»–æ‰€æœ‰åŠŸèƒ½ä¸å˜
"""

import torch
import numpy as np
import cv2
from typing import List, Tuple
import math
import os
import re
import unicodedata
from PIL import Image, ImageDraw, ImageFont



class SmartProductCollageBatch:
    """æ‰¹é‡äº§å“æ‹¼æ¥èŠ‚ç‚¹ - å¤–éƒ¨æŠ å›¾ç‰ˆ"""
    
    def __init__(self):
        self.supported_fonts = [
            "arial.ttf", 
            "simhei.ttf", 
            "PingFang.ttc",
            "wqy-microhei.ttc", 
            "msyh.ttf"
        ]

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),  # æ‰¹é‡è¾“å…¥
                "masks": ("MASK",),   # ğŸ†• æ–°å¢masksè¾“å…¥
                "images_per_collage": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 9,
                    "step": 1,
                    "display": "number"
                }),
                "layout": ([
                    "auto",
                    "horizontal",
                    "vertical",
                    "grid",
                    "adaptive_focus",  # æ™ºèƒ½ä¸»æ¬¡å¸ƒå±€ï¼šå¤§å›¾å•ç‹¬ä¸€ä¾§
                ], {"default": "auto"}),
                "output_width": ("INT", {
                    "default": 1600,
                    "min": 512,
                    "max": 4096,
                    "step": 64
                }),
                "output_height": ("INT", {
                    "default": 1600,
                    "min": 512,
                    "max": 4096,
                    "step": 64
                }),
                "spacing": ("INT", {
                    "default": 60,
                    "min": 0,
                    "max": 200,
                    "step": 10
                }),
                "min_spacing": ("INT", {
                    "default": 10,
                    "min": 0,
                    "max": 50,
                    "step": 5,
                    "display": "number"
                }),
                "outer_padding": ("INT", {
                    "default": 80,
                    "min": 0,
                    "max": 300,
                    "step": 10
                }),
                "product_scale": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.3,
                    "max": 2.0,
                    "step": 0.05
                }),
                "crop_margin": ("INT", {
                    "default": 30,
                    "min": 0,
                    "max": 100,
                    "step": 5
                }),
            },
            "optional": {
                "skip_empty": ("BOOLEAN", {"default": True}),
                "labels": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "æ”¯æŒä¸¤ç§æ ¼å¼:\n1. é€—å·åˆ†éš”: 7pcs,5pcs,3pcs\n2. æ¢è¡Œåˆ†éš”:\n7pcs\n5pcs\n3pcs"
                }),
                "label_font_size": ("INT", {
                    "default": 180,
                    "min": 20,
                    "max": 500,
                    "step": 10
                }),
                "label_position": (["bottom", "top", "none"], {"default": "bottom"}),
                "label_margin": ("INT", {
                    "default": 40,
                    "min": 0,
                    "max": 200,
                    "step": 10
                }),
                "hide_pcs_one": ("BOOLEAN", {"default": False}),
                "adaptive_direction": (["auto", "left", "right", "top", "bottom"], {"default": "auto"}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("æ‹¼æ¥å›¾æ‰¹æ¬¡",)
    FUNCTION = "batch_collage"
    CATEGORY = "image/smart_collage"

    def tensor_to_cv2(self, tensor: torch.Tensor) -> np.ndarray:
        """Tensor â†’ OpenCV"""
        while len(tensor.shape) == 4 and tensor.shape[0] == 1:
            tensor = tensor[0]
        image = tensor.cpu().numpy()
        image = (image * 255).astype(np.uint8)
        return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

    def cv2_to_tensor(self, image: np.ndarray) -> torch.Tensor:
        """OpenCV â†’ Tensor"""
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = image.astype(np.float32) / 255.0
        tensor = torch.from_numpy(image)
        # æ·»åŠ batchç»´åº¦ [H, W, 3] â†’ [1, H, W, 3]
        return tensor.unsqueeze(0)

    def mask_tensor_to_cv2(self, mask_tensor: torch.Tensor) -> np.ndarray:
        """
        Mask Tensor â†’ OpenCVæ ¼å¼
        è¾“å…¥: [H, W] æˆ– [1, H, W] çš„mask tensor (0-1èŒƒå›´)
        è¾“å‡º: [H, W] çš„numpyæ•°ç»„ (0-255èŒƒå›´)
        """
        # ç¡®ä¿æ˜¯2D
        while len(mask_tensor.shape) > 2:
            mask_tensor = mask_tensor[0]

        mask = mask_tensor.cpu().numpy()
        mask = (mask * 255).astype(np.uint8)
        return mask

    def extract_product_with_external_mask(self, image: np.ndarray, mask: np.ndarray, crop_margin: int) -> np.ndarray:
        """
        ğŸ†• ä½¿ç”¨å¤–éƒ¨maskæŠ å›¾ï¼ˆæ›¿ä»£åŸæ¥çš„extract_productæ–¹æ³•ï¼‰
        ğŸ”§ ä¿®å¤3: æ”¹è¿›é˜´å½±ä¿ç•™ç®—æ³•

        å‚æ•°:
            image: åŸå§‹å›¾ç‰‡ [H, W, 3]
            mask: å¤–éƒ¨æä¾›çš„mask [H, W] (0-255)
            crop_margin: è£å‰ªè¾¹è·

        è¿”å›:
            æŠ å‡ºçš„äº§å“å›¾ç‰‡ [H, W, 3]
        """
        # å°†maskæ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
        normalized_mask = mask.astype(np.float32) / 255.0

        # ğŸ”§ ä¿®å¤3: ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼æ¥ä¿ç•™é˜´å½±
        soft_threshold = 0.05  # ä»0.1é™ä½åˆ°0.05
        soft_mask = np.where(normalized_mask > soft_threshold, normalized_mask, 0)

        # æ‰¾åˆ°æœ‰æ•ˆåŒºåŸŸçš„è½®å»“ï¼ˆç”¨äºè¾¹ç•Œæ¡†è®¡ç®—ï¼‰
        binary_mask_for_bbox = (normalized_mask > 0.2).astype(np.uint8) * 255  # ä»0.3é™ä½åˆ°0.2
        contours, _ = cv2.findContours(binary_mask_for_bbox, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è½®å»“ï¼Œè¿”å›åŸå›¾
            return image

        # è®¡ç®—æ‰€æœ‰è½®å»“çš„è¾¹ç•Œæ¡†
        x, y, w, h = cv2.boundingRect(np.vstack(contours))

        # æ·»åŠ è¾¹è·
        margin_x = int(w * crop_margin / 100)
        margin_y = int(h * crop_margin / 100)

        x = max(0, x - margin_x)
        y = max(0, y - margin_y)
        w = min(image.shape[1] - x, w + 2 * margin_x)
        h = min(image.shape[0] - y, h + 2 * margin_y)

        # è£å‰ªå›¾ç‰‡å’Œmask
        cropped_image = image[y:y+h, x:x+w]
        cropped_mask = soft_mask[y:y+h, x:x+w]

        # ğŸ”§ ä¿®å¤3: æ”¹è¿›é˜´å½±ä¿ç•™çš„åˆæˆç®—æ³•
        # ä½¿ç”¨éçº¿æ€§å˜æ¢å¢å¼ºé˜´å½±åŒºåŸŸçš„ä¿ç•™åº¦
        # å¯¹maskåº”ç”¨å¹‚å‡½æ•°ï¼Œä½¿ä½å€¼åŒºåŸŸï¼ˆé˜´å½±ï¼‰å¾—åˆ°æ›´é«˜çš„æƒé‡
        enhanced_mask = np.power(cropped_mask, 0.5)  # å¹³æ–¹æ ¹å˜æ¢ï¼Œè®©0.1å˜æˆ0.316ï¼Œ0.2å˜æˆ0.447

        # åˆ›å»ºç™½è‰²èƒŒæ™¯
        result = np.ones_like(cropped_image) * 255

        # æ‰©å±•maskåˆ°3é€šé“
        mask_3channel = np.stack([enhanced_mask, enhanced_mask, enhanced_mask], axis=2)

        # ä½¿ç”¨å¢å¼ºåçš„maskè¿›è¡Œæ··åˆï¼Œæ›´å¥½åœ°ä¿ç•™é˜´å½±
        result = cropped_image * mask_3channel + result * (1 - mask_3channel)

        return result.astype(np.uint8)

    def get_product_features(self, product: np.ndarray) -> Tuple[float, float, float, bool]:
        """
        ğŸ”§ ä¿®å¤3: æ”¹è¿›é“¾æ¡è¯†åˆ«ç®—æ³• - ä¼˜å…ˆè¯†åˆ«å¼€æ”¾æ€§é“¾æ¡

        è¿”å›: (area_ratio, aspect_ratio, edge_density, is_chain)
        """
        h, w = product.shape[:2]
        gray = cv2.cvtColor(product, cv2.COLOR_BGR2GRAY)

        # è®¡ç®—éç™½è‰²åŒºåŸŸé¢ç§¯
        mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)[1]
        area_ratio = np.sum(mask > 0) / (h * w)

        # å®½é«˜æ¯”
        aspect_ratio = w / h

        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 30, 100)
        edge_density = np.sum(edges > 0) / (h * w)

        # ğŸ”§ ä¿®å¤3: é“¾æ¡ç‰¹å¾æ£€æµ‹ - é‡ç‚¹æ£€æµ‹å¼€æ”¾æ€§é“¾æ¡
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        is_chain = False
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)

            # æ£€æµ‹å¼€æ”¾è¾¹ç¼˜ - é“¾æ¡é€šå¸¸æœ‰æ–­å¼€çš„éƒ¨åˆ†
            hull = cv2.convexHull(largest_contour)
            hull_area = cv2.contourArea(hull)
            contour_area = cv2.contourArea(largest_contour)
            solidity = contour_area / hull_area if hull_area > 0 else 0

            # è®¡ç®—è½®å»“çš„ç´§å¯†åº¦ï¼ˆå‘¨é•¿Â²/é¢ç§¯ï¼‰
            perimeter = cv2.arcLength(largest_contour, True)
            elongation_factor = (perimeter ** 2) / contour_area if contour_area > 0 else 0

            # æ£€æµ‹è¾¹ç•Œæ¥è§¦ - é“¾æ¡å¸¸å¸¸å»¶ä¼¸åˆ°å›¾åƒè¾¹ç¼˜
            x, y, w_box, h_box = cv2.boundingRect(largest_contour)
            touches_edge = (x <= 5 or y <= 5 or x + w_box >= w - 5 or y + h_box >= h - 5)

            # ğŸ”§ ä¿®å¤3: å¼€æ”¾æ€§æ£€æµ‹ - æ£€æµ‹è½®å»“çš„å¼€æ”¾ç¨‹åº¦
            # è®¡ç®—è½®å»“çš„å‡¸æ€§ç¼ºé™·
            defects = cv2.convexityDefects(largest_contour, cv2.convexHull(largest_contour, returnPoints=False))
            major_defects = 0
            if defects is not None:
                for i in range(defects.shape[0]):
                    s, e, f, d = defects[i, 0]
                    if d > 1000:  # è¾ƒå¤§çš„å‡¸æ€§ç¼ºé™·è¡¨ç¤ºå¼€æ”¾æ€§
                        major_defects += 1

            # ğŸ”§ ä¿®å¤3: é“¾æ¡åˆ¤æ–­æ¡ä»¶ï¼ˆé’ˆå¯¹é¦–é¥°ç±»äº§å“ä¼˜åŒ–ï¼‰
            chain_score = 0

            # 1. å¼€æ”¾æ€§ç‰¹å¾ï¼ˆæœ€é‡è¦ï¼‰
            if major_defects >= 2:  # æœ‰å¤šä¸ªæ˜æ˜¾çš„å¼€å£/å‡¹é™·
                chain_score += 4
            elif major_defects >= 1:
                chain_score += 2

            # 2. ç»†é•¿ç‰¹å¾
            if elongation_factor > 20:  # æåº¦ç»†é•¿
                chain_score += 3
            elif elongation_factor > 15:
                chain_score += 2

            # 3. ä½å¯†å®åº¦ï¼ˆæœ‰å¾ˆå¤šç©ºéš™ï¼‰
            if solidity < 0.7:
                chain_score += 2
            elif solidity < 0.8:
                chain_score += 1

            # 4. æ¥è§¦è¾¹ç¼˜
            if touches_edge:
                chain_score += 2

            # 5. å®½é«˜æ¯”ç‰¹å¾ï¼ˆé¦–é¥°é“¾æ¡é€šå¸¸å¾ˆé•¿ï¼‰
            if aspect_ratio > 2.5 or aspect_ratio < 0.4:
                chain_score += 2
            elif aspect_ratio > 1.8 or aspect_ratio < 0.6:
                chain_score += 1

            # 6. ä½é¢ç§¯ä½†é«˜è¾¹ç¼˜å¯†åº¦ï¼ˆç»†é“¾æ¡ç‰¹å¾ï¼‰
            if area_ratio < 0.15 and edge_density > 0.08:
                chain_score += 2
            elif area_ratio < 0.25 and edge_density > 0.06:
                chain_score += 1

            # ğŸ”§ ä¿®å¤3: é™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“è¯†åˆ«å¼€æ”¾æ€§é“¾æ¡
            is_chain = chain_score >= 4  # ä»5é™ä½åˆ°4ï¼Œæ›´å®¹æ˜“è¯†åˆ«é“¾æ¡

            print(f"     é“¾æ¡æ£€æµ‹: ç»†é•¿åº¦={elongation_factor:.1f}, å¯†å®åº¦={solidity:.3f}, "
                  f"å¼€æ”¾ç¼ºé™·={major_defects}, æ¥è§¦è¾¹ç¼˜={touches_edge}, å¾—åˆ†={chain_score}, "
                  f"åˆ¤å®š={'å¼€æ”¾é“¾æ¡' if is_chain else 'éé“¾æ¡'}")

        return area_ratio, aspect_ratio, edge_density, is_chain

    def decide_layout(self, num_products: int, layout: str, products: List[np.ndarray] = None) -> str:
        """
        å†³å®šå¸ƒå±€æ–¹å¼

        Args:
            num_products: å›¾ç‰‡æ•°é‡
            layout: ç”¨æˆ·é€‰æ‹©çš„å¸ƒå±€æ¨¡å¼
            products: äº§å“å›¾ç‰‡åˆ—è¡¨ï¼ˆç”¨äºæ™ºèƒ½åˆ¤æ–­ï¼‰

        Returns:
            æœ€ç»ˆå¸ƒå±€æ¨¡å¼
        """
        if layout != "auto" and layout != "adaptive_focus":
            return layout
        # auto: è‡ªåŠ¨é€‰æ‹©
        if num_products == 1:
            return "single"
        elif num_products == 2:
            return "horizontal"
        elif num_products >= 4:
            return "grid"
        # adaptive_focus: æ™ºèƒ½ä¸»æ¬¡å¸ƒå±€ï¼ˆä½¿ç”¨å¢å¼ºçš„é“¾æ¡è¯†åˆ«ï¼‰
        if layout == "auto":
            if num_products > 2 and products:
                # ğŸ”§ ä½¿ç”¨å¢å¼ºçš„é“¾æ¡è¯†åˆ«ç®—æ³•åˆ¤æ–­
                has_necklace = False

                for p in products:
                    h, w = p.shape[:2]
                    aspect_ratio = w / h

                    # æ£€æµ‹é“¾æ¡ç‰¹å¾
                    if aspect_ratio > 1.3 or aspect_ratio < 0.77:
                        gray = cv2.cvtColor(p, cv2.COLOR_BGR2GRAY)
                        edges = cv2.Canny(gray, 30, 100)

                        h_margin = max(1, int(h * 0.05))
                        w_margin = max(1, int(w * 0.05))

                        top_density = np.sum(edges[0:h_margin, :]) / (h_margin * w)
                        bottom_density = np.sum(edges[-h_margin:, :]) / (h_margin * w)
                        left_density = np.sum(edges[:, 0:w_margin]) / (h * w_margin)
                        right_density = np.sum(edges[:, -w_margin:]) / (h * w_margin)

                        edge_touches = sum([
                            top_density > 0.05,
                            bottom_density > 0.05,
                            left_density > 0.05,
                            right_density > 0.05
                        ])

                        if edge_touches >= 2:
                            has_necklace = True
                            break

                # å¦‚æœæ£€æµ‹åˆ°é“¾æ¡ï¼Œä½¿ç”¨adaptive_focus
                if has_necklace:
                    return "adaptive_focus"

                # å¦åˆ™æŒ‰é¢ç§¯åˆ¤æ–­
                areas = [p.shape[0] * p.shape[1] for p in products]
                sorted_areas = sorted(areas, reverse=True)
                if len(sorted_areas) >= 2 and sorted_areas[0] > sorted_areas[1] * 1.5:
                    return "adaptive_focus"
            return "grid"

    def preprocess_label(self, text: str) -> str:
        """é¢„å¤„ç†æ ‡ç­¾æ–‡æœ¬ï¼šç»Ÿä¸€å…¨è§’å­—ç¬¦"""
        if not text:
            return ""

        # æ›¿æ¢å¸¸è§çš„åŠè§’ç¬¦å·ä¸ºå…¨è§’
        replacements = {
            'x': 'Ã—',  # åŠè§’xæ›¿æ¢ä¸ºä¹˜å·
            'X': 'Ã—',  # å¤§å†™Xä¹Ÿæ›¿æ¢
            '*': 'Ã—',  # æ˜Ÿå·æ›¿æ¢ä¸ºä¹˜å·
        }

        result = text
        for half, full in replacements.items():
            result = result.replace(half, full)

        return result

    def get_available_font(self, size: int):
        """è·å–å¯ç”¨å­—ä½“ï¼Œæ”¯æŒä¸­æ–‡"""
        # å¸¸è§ç³»ç»Ÿå­—ä½“è·¯å¾„
        font_paths = [
            # Windows
            "C:/Windows/Fonts/simhei.ttf",
            "C:/Windows/Fonts/msyh.ttc",
            "C:/Windows/Fonts/arial.ttf",
            # macOS
            "/System/Library/Fonts/PingFang.ttc",
            "/System/Library/Fonts/Arial.ttf",
            # Linux
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/wqy-microhei.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"
        ]

        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    return ImageFont.truetype(font_path, size)
                except:
                    continue

        # ä½¿ç”¨é»˜è®¤å­—ä½“
        try:
            return ImageFont.load_default()
        except:
            return ImageFont.load_default()

    def add_label(self, product: np.ndarray, label: str, position: str, font_size: int, margin: int) -> np.ndarray:
        """ä¸ºäº§å“æ·»åŠ æ ‡ç­¾"""
        if not label or position == "none":
            return product

        h, w = product.shape[:2]

        # è½¬æ¢ä¸ºPILå¤„ç†æ–‡å­—
        pil_img = Image.fromarray(cv2.cvtColor(product, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)

        # è·å–å­—ä½“
        font = self.get_available_font(font_size)

        # è®¡ç®—æ–‡å­—å°ºå¯¸
        bbox = draw.textbbox((0, 0), label, font=font)
        text_w = bbox[2] - bbox[0]
        text_h = bbox[3] - bbox[1]

        # ğŸ”§ ä¿®å¤2: æ›´æ™ºèƒ½çš„å­—ä½“å¤§å°è°ƒæ•´ï¼ŒåŸºäºäº§å“å®é™…å°ºå¯¸
        if text_w > w * 0.8:
            scale = (w * 0.8) / text_w
            new_font_size = max(20, int(font_size * scale))
            font = self.get_available_font(new_font_size)
            bbox = draw.textbbox((0, 0), label, font=font)
            text_w = bbox[2] - bbox[0]
            text_h = bbox[3] - bbox[1]

        # ğŸ”§ ä¿®å¤2: ç¡®ä¿æ ‡ç­¾åŒºåŸŸè¶³å¤Ÿå¤§ï¼Œé˜²æ­¢è¢«é®æŒ¡
        label_area_height = max(text_h + 20, int(h * 0.15))  # è‡³å°‘æ˜¯äº§å“é«˜åº¦çš„15%

        # åˆ›å»ºæ–°ç”»å¸ƒ
        if position == "bottom":
            new_h = h + label_area_height + margin
            new_img = Image.new('RGB', (w, new_h), (255, 255, 255))
            new_img.paste(pil_img, (0, 0))
            text_x = (w - text_w) // 2
            text_y = h + margin + (label_area_height - text_h) // 2  # åœ¨æ ‡ç­¾åŒºåŸŸå†…å±…ä¸­
        else:  # top
            new_h = h + label_area_height + margin
            new_img = Image.new('RGB', (w, new_h), (255, 255, 255))
            new_img.paste(pil_img, (0, label_area_height + margin))
            text_x = (w - text_w) // 2
            text_y = (label_area_height - text_h) // 2  # åœ¨æ ‡ç­¾åŒºåŸŸå†…å±…ä¸­

        # ç»˜åˆ¶æ–‡å­—
        draw = ImageDraw.Draw(new_img)
        draw.text((text_x, text_y), label, font=font, fill=(0, 0, 0))

        # è½¬æ¢å›OpenCV
        return cv2.cvtColor(np.array(new_img), cv2.COLOR_RGB2BGR)

    def create_collage(self, products: List[np.ndarray], layout: str, output_width: int,
                      output_height: int, spacing: int, padding: int, scale_factor: float,
                      adaptive_direction: str = "auto", min_spacing: int = 10) -> np.ndarray:
        """åˆ›å»ºæ‹¼æ¥å›¾"""
        if not products:
            return np.ones((output_height, output_width, 3), dtype=np.uint8) * 255

        if layout == "single":
            return self.create_single_layout(products[0], output_width, output_height, padding, scale_factor)
        elif layout == "horizontal":
            return self.create_horizontal_layout(products, output_width, output_height, spacing, padding, scale_factor, min_spacing)
        elif layout == "vertical":
            return self.create_vertical_layout(products, output_width, output_height, spacing, padding, scale_factor)
        elif layout == "grid":
            return self.create_grid_layout(products, output_width, output_height, spacing, padding, scale_factor)
        elif layout == "adaptive_focus":
            return self.create_adaptive_focus_layout(products, output_width, output_height, spacing, padding, scale_factor, adaptive_direction)
        else:
            return self.create_grid_layout(products, output_width, output_height, spacing, padding, scale_factor)

    def create_single_layout(self, product: np.ndarray, canvas_w: int, canvas_h: int,
                           padding: int, scale_factor: float) -> np.ndarray:
        """å•ä¸ªäº§å“å±…ä¸­å¸ƒå±€"""
        h, w = product.shape[:2]

        # è®¡ç®—å¯ç”¨ç©ºé—´
        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_x = available_w / w
        scale_y = available_h / h
        scale = min(scale_x, scale_y) * scale_factor

        # ç¼©æ”¾å›¾ç‰‡
        new_w = max(1, int(w * scale))
        new_h = max(1, int(h * scale))
        resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)

        # åˆ›å»ºç”»å¸ƒå¹¶å±…ä¸­æ”¾ç½®
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
        x = (canvas_w - new_w) // 2
        y = (canvas_h - new_h) // 2

        if 0 <= x < canvas_w - new_w and 0 <= y < canvas_h - new_h:
            canvas[y:y+new_h, x:x+new_w] = resized

        return canvas

    def create_horizontal_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                               spacing: int, padding: int, scale_factor: float, min_spacing: int = 10) -> np.ndarray:
        """æ°´å¹³å¸ƒå±€"""
        # è®¡ç®—æ€»å®½åº¦å’Œæœ€å¤§é«˜åº¦
        total_w = sum([p.shape[1] for p in products])
        max_h = max([p.shape[0] for p in products])

        # ğŸ”§ ä¿®å¤1: å‡å°‘é—´è·ï¼Œä½¿ç”¨å¯è°ƒèŠ‚çš„æœ€å°é—´è·å‚æ•°
        actual_spacing = max(spacing, min_spacing)  # ä½¿ç”¨å¯è°ƒèŠ‚çš„æœ€å°é—´è·ï¼Œæ›´ç´§å‡‘

        # è®¡ç®—å¯ç”¨ç©ºé—´
        available_w = canvas_w - 2 * padding - actual_spacing * (len(products) - 1)
        available_h = canvas_h - 2 * padding

        # è®¡ç®—ç»Ÿä¸€ç¼©æ”¾æ¯”ä¾‹
        scale_x = available_w / total_w
        scale_y = available_h / max_h
        scale = min(scale_x, scale_y) * scale_factor

        # ç¼©æ”¾æ‰€æœ‰äº§å“
        resized_products = []
        for product in products:
            h, w = product.shape[:2]
            new_w = max(1, int(w * scale))
            new_h = max(1, int(h * scale))
            resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            resized_products.append(resized)

        # è®¡ç®—å®é™…ä½¿ç”¨çš„æ€»å®½åº¦
        actual_w = sum([p.shape[1] for p in resized_products]) + actual_spacing * (len(products) - 1)
        max_resized_h = max([p.shape[0] for p in resized_products])

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # å±…ä¸­èµ·å§‹ä½ç½®
        start_x = (canvas_w - actual_w) // 2
        start_y = (canvas_h - max_resized_h) // 2

        # ä¾æ¬¡æ”¾ç½®äº§å“
        current_x = start_x
        for product in resized_products:
            h, w = product.shape[:2]
            y = start_y + (max_resized_h - h) // 2  # å‚ç›´å±…ä¸­

            if 0 <= y < canvas_h - h and 0 <= current_x < canvas_w - w:
                canvas[y:y+h, current_x:current_x+w] = product

            current_x += w + actual_spacing

        return canvas

    def create_vertical_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                             spacing: int, padding: int, scale_factor: float) -> np.ndarray:
        """å‚ç›´å¸ƒå±€"""
        total_h = sum([p.shape[0] for p in products])
        max_w = max([p.shape[1] for p in products])

        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding - spacing * (len(products) - 1)

        scale_x = available_w / max_w
        scale_y = available_h / total_h
        scale = min(scale_x, scale_y) * scale_factor

        resized_products = []
        for product in products:
            h, w = product.shape[:2]
            new_w = max(1, int(w * scale))
            new_h = max(1, int(h * scale))
            resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            resized_products.append(resized)

        actual_h = sum([p.shape[0] for p in resized_products]) + spacing * (len(products) - 1)
        max_resized_w = max([p.shape[1] for p in resized_products])

        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        start_x = (canvas_w - max_resized_w) // 2
        start_y = (canvas_h - actual_h) // 2

        current_y = start_y
        for product in resized_products:
            h, w = product.shape[:2]
            x = start_x + (max_resized_w - w) // 2

            if 0 <= x < canvas_w - w and 0 <= current_y < canvas_h - h:
                canvas[current_y:current_y+h, x:x+w] = product

            current_y += h + spacing

        return canvas

    def create_grid_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                          spacing: int, padding: int, scale_factor: float) -> np.ndarray:
        """ç½‘æ ¼å¸ƒå±€"""
        n = len(products)
        if n <= 1:
            return self.create_single_layout(products[0], canvas_w, canvas_h, padding, scale_factor)
        elif n == 2:
            return self.create_horizontal_layout(products, canvas_w, canvas_h, spacing, padding, scale_factor)
        elif n == 3:
            # 2+1å¸ƒå±€
            rows, cols = 2, 2
        elif n == 4:
            rows, cols = 2, 2
        elif n <= 6:
            rows, cols = 2, 3
        elif n <= 9:
            rows, cols = 3, 3
        else:
            # è¶…è¿‡9ä¸ªï¼Œå–å‰9ä¸ª
            products = products[:9]
            rows, cols = 3, 3

        # è®¡ç®—æ¯ä¸ªæ ¼å­çš„å¤§å°
        available_w = canvas_w - 2 * padding - spacing * (cols - 1)
        available_h = canvas_h - 2 * padding - spacing * (rows - 1)
        cell_w = available_w // cols
        cell_h = available_h // rows

        # è®¡ç®—äº§å“çš„ç»Ÿä¸€ç¼©æ”¾æ¯”ä¾‹
        max_product_w = max([p.shape[1] for p in products])
        max_product_h = max([p.shape[0] for p in products])

        scale_x = cell_w / max_product_w
        scale_y = cell_h / max_product_h
        scale = min(scale_x, scale_y) * scale_factor

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # æ”¾ç½®äº§å“
        for i, product in enumerate(products):
            row = i // cols
            col = i % cols

            # ç¼©æ”¾äº§å“
            h, w = product.shape[:2]
            new_w = max(1, int(w * scale))
            new_h = max(1, int(h * scale))
            resized = cv2.resize(product, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)

            # è®¡ç®—ä½ç½®ï¼ˆåœ¨æ ¼å­å†…å±…ä¸­ï¼‰
            cell_x = padding + col * (cell_w + spacing)
            cell_y = padding + row * (cell_h + spacing)

            x = cell_x + (cell_w - new_w) // 2
            y = cell_y + (cell_h - new_h) // 2

            if 0 <= x < canvas_w - new_w and 0 <= y < canvas_h - new_h:
                canvas[y:y+new_h, x:x+new_w] = resized

        return canvas

    def create_adaptive_focus_layout(self, products: List[np.ndarray], canvas_w: int, canvas_h: int,
                                   spacing: int, padding: int, scale_factor: float, adaptive_direction: str = "auto") -> np.ndarray:
        """
        ğŸ”§ æ™ºèƒ½ä¸»æ¬¡å¸ƒå±€ - å¢å¼ºé“¾æ¡è¯†åˆ«ï¼ˆæ¥è‡ªaaa.pyï¼‰

        Args:
            direction: ä¸»äº§å“æ”¾ç½®æ–¹å‘ (auto/left/right/top/bottom)
        """
        if len(products) < 2:
            return self.create_single_layout(products[0], canvas_w, canvas_h, padding, scale_factor)

        # ğŸ”§ æ™ºèƒ½åˆ¤æ–­ä¸»äº§å“ - å¢å¼ºç‰ˆ
        product_features = []
        for i, p in enumerate(products):
            h, w = p.shape[:2]
            area = h * w
            aspect_ratio = w / h  # å®½é«˜æ¯”

            # ğŸ”§ å¢å¼ºé“¾æ¡æ£€æµ‹
            is_necklace = False
            necklace_score = 0

            # ç‰¹å¾1: æç«¯å®½é«˜æ¯”ï¼ˆæ›´å®½æ¾çš„é˜ˆå€¼ï¼‰
            if aspect_ratio > 1.3 or aspect_ratio < 0.77:  # ä»1.5/0.67æ”¹ä¸º1.3/0.77
                necklace_score += 30

            # ç‰¹å¾2: è¾¹ç¼˜å»¶ä¼¸æ£€æµ‹ï¼ˆé™ä½æ£€æµ‹é˜ˆå€¼ï¼‰
            gray = cv2.cvtColor(p, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 30, 100)  # ä»50/150é™ä½åˆ°30/100ï¼Œæ›´æ•æ„Ÿ

            h_margin = max(1, int(h * 0.05))  # æ£€æµ‹è¾¹ç¼˜çš„èŒƒå›´
            w_margin = max(1, int(w * 0.05))

            # æ£€æµ‹å››ä¸ªè¾¹ç¼˜åŒºåŸŸçš„è¾¹ç¼˜å¯†åº¦
            top_density = np.sum(edges[0:h_margin, :]) / (h_margin * w)
            bottom_density = np.sum(edges[-h_margin:, :]) / (h_margin * w)
            left_density = np.sum(edges[:, 0:w_margin]) / (h * w_margin)
            right_density = np.sum(edges[:, -w_margin:]) / (h * w_margin)

            # è¾¹ç¼˜å¯†åº¦é˜ˆå€¼ï¼ˆé™ä½é˜ˆå€¼æ›´å®¹æ˜“æ£€æµ‹ï¼‰
            density_threshold = 0.05  # ä»0.1é™ä½åˆ°0.05

            edge_touches = 0
            if top_density > density_threshold:
                edge_touches += 1
                necklace_score += 25
            if bottom_density > density_threshold:
                edge_touches += 1
                necklace_score += 25
            if left_density > density_threshold:
                edge_touches += 1
                necklace_score += 25
            if right_density > density_threshold:
                edge_touches += 1
                necklace_score += 25

            # å¦‚æœè‡³å°‘æœ‰2ä¸ªè¾¹ç¼˜æœ‰å»¶ä¼¸ï¼Œåˆ¤å®šä¸ºé“¾æ¡
            if edge_touches >= 2:
                is_necklace = True
                necklace_score += 50

            # ç‰¹å¾3: ç»†é•¿åº¦ï¼ˆå‘¨é•¿/é¢ç§¯æ¯”ï¼‰
            contours, _ = cv2.findContours(
                cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)[1],
                cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            )
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                perimeter = cv2.arcLength(largest_contour, True)
                if area > 0:
                    slenderness = perimeter * perimeter / area
                    if slenderness > 50:  # ç»†é•¿åº¦é«˜
                        necklace_score += 30
                        is_necklace = True

            product_features.append({
                'index': i,
                'area': area,
                'aspect_ratio': aspect_ratio,
                'is_necklace': is_necklace,
                'necklace_score': necklace_score,
                'edge_touches': edge_touches,
                'score': 0
            })

        # è®¡ç®—ç»¼åˆå¾—åˆ†
        max_area = max([f['area'] for f in product_features])
        for feature in product_features:
            score = 0

            # é¢ç§¯å¾—åˆ†ï¼ˆæƒé‡é™ä½ï¼‰
            score += (feature['area'] / max_area) * 30

            # é“¾æ¡å¾—åˆ†ï¼ˆæƒé‡æé«˜ï¼‰
            score += feature['necklace_score']

            feature['score'] = score

        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ä½œä¸ºä¸»äº§å“
        product_features.sort(key=lambda x: x['score'], reverse=True)
        max_idx = product_features[0]['index']

        # è°ƒè¯•ä¿¡æ¯
        print(f"   ğŸ” ä¸»äº§å“è¯†åˆ«:")
        for i, f in enumerate(product_features):
            mark = "ğŸ‘‘ä¸»" if i == 0 else "  "
            print(f"      {mark} äº§å“{f['index']+1}: å¾—åˆ†{f['score']:.1f} "
                  f"(é“¾æ¡:{f['is_necklace']}, è¾¹ç¼˜:{f['edge_touches']}, "
                  f"å®½é«˜æ¯”:{f['aspect_ratio']:.2f})")

        main_product = products[max_idx]
        other_products = [p for i, p in enumerate(products) if i != max_idx]

        # ğŸ”§ ä¿®å¤ï¼šé“¾æ¡ç±»äº§å“ä¼˜å…ˆæ”¾ä¸Šæ–¹
        if adaptive_direction == "auto":
            if product_features[0]['is_necklace']:
                adaptive_direction = "top"
                print(f"   ğŸ“ æ£€æµ‹åˆ°é“¾æ¡ç±»äº§å“ï¼Œè‡ªåŠ¨æ”¾ç½®ä¸Šæ–¹")
            elif canvas_w > canvas_h * 1.2:
                adaptive_direction = "left" if len(other_products) <= 2 else "top"
            elif canvas_h > canvas_w * 1.2:
                adaptive_direction = "top" if len(other_products) <= 2 else "left"
            else:
                adaptive_direction = "left" if len(other_products) <= 3 else "top"

        # æ ¹æ®æ–¹å‘é€‰æ‹©å¸ƒå±€å‡½æ•°
        if adaptive_direction == "left":
            return self.create_adaptive_horizontal_split(main_product, other_products, canvas_w, canvas_h,
                                                  spacing, padding, scale_factor, main_on_left=True)
        elif adaptive_direction == "right":
            return self.create_adaptive_horizontal_split(main_product, other_products, canvas_w, canvas_h,
                                                  spacing, padding, scale_factor, main_on_left=False)
        elif adaptive_direction == "top":
            return self.create_adaptive_vertical_split(main_product, other_products, canvas_w, canvas_h,
                                                spacing, padding, scale_factor, main_on_top=True)
        elif adaptive_direction == "bottom":
            return self.create_adaptive_vertical_split(main_product, other_products, canvas_w, canvas_h,
                                                spacing, padding, scale_factor, main_on_top=False)
        else:
            return self.create_adaptive_horizontal_split(main_product, other_products, canvas_w, canvas_h,
                                                  spacing, padding, scale_factor, main_on_left=True)

    def create_adaptive_horizontal_split(self, main_product: np.ndarray, other_products: List[np.ndarray],
                                   canvas_w: int, canvas_h: int, spacing: int,
                                   padding: int, scale_factor: float, main_on_left: bool = True) -> np.ndarray:
        """
        å·¦å³åˆ†å‰²å¸ƒå±€ï¼ˆæ¥è‡ªaaa.pyï¼‰
        Args:
            main_on_left: True=ä¸»äº§å“åœ¨å·¦ï¼ŒFalse=ä¸»äº§å“åœ¨å³
        """
        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding

        # ä¸»äº§å“å 45%å®½åº¦
        main_w = int(available_w * 0.45)
        other_w = available_w - main_w - spacing

        # ç¼©æ”¾ä¸»äº§å“
        mh, mw = main_product.shape[:2]
        main_scale = min(main_w / mw, available_h / mh) * scale_factor
        main_new_w = max(1, int(mw * main_scale))
        main_new_h = max(1, int(mh * main_scale))
        main_resized = cv2.resize(main_product, (main_new_w, main_new_h), interpolation=cv2.INTER_LANCZOS4)

        # ç¼©æ”¾å…¶ä»–äº§å“ï¼ˆç«–æ’ï¼‰
        num_others = len(other_products)
        other_spacing = spacing * (num_others - 1)

        max_original_w = max([p.shape[1] for p in other_products])
        total_original_h = sum([p.shape[0] for p in other_products])

        scale_by_width = other_w / max_original_w
        scale_by_height = (available_h - other_spacing) / total_original_h
        unified_scale = min(scale_by_width, scale_by_height) * scale_factor

        others_resized = []
        for p in other_products:
            h, w = p.shape[:2]
            new_w = max(1, int(w * unified_scale))
            new_h = max(1, int(h * unified_scale))
            others_resized.append(cv2.resize(p, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4))

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # å†³å®šä½ç½®
        if main_on_left:
            # ä¸»äº§å“åœ¨å·¦
            main_x = padding
            others_start_x = padding + main_w + spacing
        else:
            # ä¸»äº§å“åœ¨å³
            main_x = padding + other_w + spacing
            others_start_x = padding

        # æ”¾ç½®ä¸»äº§å“ï¼ˆå±…ä¸­ï¼‰
        main_y = (canvas_h - main_new_h) // 2
        if 0 <= main_x < canvas_w - main_new_w and 0 <= main_y < canvas_h - main_new_h:
            canvas[main_y:main_y+main_new_h, main_x:main_x+main_new_w] = main_resized

        # æ”¾ç½®å…¶ä»–äº§å“ï¼ˆç«–æ’å±…ä¸­ï¼‰
        total_other_h = sum([img.shape[0] for img in others_resized]) + other_spacing
        max_other_w = max([img.shape[1] for img in others_resized])

        start_y = (canvas_h - total_other_h) // 2
        start_x = others_start_x + (other_w - max_other_w) // 2

        current_y = start_y
        for img in others_resized:
            h, w = img.shape[:2]
            x = start_x + (max_other_w - w) // 2
            if 0 <= x < canvas_w - w and 0 <= current_y < canvas_h - h:
                canvas[current_y:current_y+h, x:x+w] = img
            current_y += h + spacing

        return canvas

    def create_adaptive_vertical_split(self, main_product: np.ndarray, other_products: List[np.ndarray],
                                canvas_w: int, canvas_h: int, spacing: int,
                                padding: int, scale_factor: float, main_on_top: bool = True) -> np.ndarray:
        """
        ä¸Šä¸‹åˆ†å‰²å¸ƒå±€ï¼ˆæ¥è‡ªaaa.pyï¼‰
        Args:
            main_on_top: True=ä¸»äº§å“åœ¨ä¸Šï¼ŒFalse=ä¸»äº§å“åœ¨ä¸‹
        """
        available_w = canvas_w - 2 * padding
        available_h = canvas_h - 2 * padding

        # ä¸»äº§å“å 45%é«˜åº¦
        main_h = int(available_h * 0.45)
        other_h = available_h - main_h - spacing

        # ç¼©æ”¾ä¸»äº§å“
        mh, mw = main_product.shape[:2]
        main_scale = min(available_w / mw, main_h / mh) * scale_factor
        main_new_w = max(1, int(mw * main_scale))
        main_new_h = max(1, int(mh * main_scale))
        main_resized = cv2.resize(main_product, (main_new_w, main_new_h), interpolation=cv2.INTER_LANCZOS4)

        # ç¼©æ”¾å…¶ä»–äº§å“ï¼ˆæ¨ªæ’ï¼‰
        num_others = len(other_products)
        other_spacing = spacing * (num_others - 1)

        total_original_w = sum([p.shape[1] for p in other_products])
        max_original_h = max([p.shape[0] for p in other_products])

        scale_by_width = (available_w - other_spacing) / total_original_w
        scale_by_height = other_h / max_original_h
        unified_scale = min(scale_by_width, scale_by_height) * scale_factor

        others_resized = []
        for p in other_products:
            h, w = p.shape[:2]
            new_w = max(1, int(w * unified_scale))
            new_h = max(1, int(h * unified_scale))
            others_resized.append(cv2.resize(p, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4))

        # åˆ›å»ºç”»å¸ƒ
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # å†³å®šä½ç½®
        if main_on_top:
            # ä¸»äº§å“åœ¨ä¸Š
            main_y = padding
            others_start_y = padding + main_h + spacing
        else:
            # ä¸»äº§å“åœ¨ä¸‹
            main_y = padding + other_h + spacing
            others_start_y = padding

        # æ”¾ç½®ä¸»äº§å“ï¼ˆå±…ä¸­ï¼‰
        main_x = (canvas_w - main_new_w) // 2
        if 0 <= main_x < canvas_w - main_new_w and 0 <= main_y < canvas_h - main_new_h:
            canvas[main_y:main_y+main_new_h, main_x:main_x+main_new_w] = main_resized

        # æ”¾ç½®å…¶ä»–äº§å“ï¼ˆæ¨ªæ’å±…ä¸­ï¼‰
        total_other_w = sum([img.shape[1] for img in others_resized]) + other_spacing
        max_other_h = max([img.shape[0] for img in others_resized])

        start_x = (canvas_w - total_other_w) // 2
        start_y = others_start_y + (other_h - max_other_h) // 2

        current_x = start_x
        for img in others_resized:
            h, w = img.shape[:2]
            y = start_y + (max_other_h - h) // 2
            if 0 <= y < canvas_h - h and 0 <= current_x < canvas_w - w:
                canvas[y:y+h, current_x:current_x+w] = img
            current_x += w + spacing

        return canvas

    def batch_collage(self, images, masks, images_per_collage, layout, output_width, output_height,
                     spacing, min_spacing, outer_padding, product_scale, crop_margin,
                     skip_empty=True, labels="", label_font_size=180,
                     label_position="bottom", label_margin=40, hide_pcs_one=False, adaptive_direction="auto"):
        """
        æ‰¹é‡æ‹¼æ¥ä¸»å‡½æ•° - å¤–éƒ¨æŠ å›¾ç‰ˆ

        ğŸ†• ä¿®æ”¹: æ–°å¢maskså‚æ•°ï¼Œå»æ‰å†…éƒ¨æŠ å›¾æµç¨‹

        å‚æ•°:
            images: è¾“å…¥çš„å›¾ç‰‡batch [N, H, W, C]
            masks: è¾“å…¥çš„mask batch [N, H, W] ğŸ†•
            images_per_collage: æ¯å¼ æ‹¼æ¥å›¾åŒ…å«å¤šå°‘å¼ åŸå›¾
            labels: æ ‡ç­¾æ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ªæ ‡ç­¾
            label_font_size: æ ‡ç­¾å­—ä½“å¤§å°
            label_position: æ ‡ç­¾ä½ç½® (bottom/top/none)
            label_margin: æ ‡ç­¾ä¸äº§å“çš„é—´è·
            hide_pcs_one: å½“æ ‡ç­¾ä¸º"Ã—1"æˆ–"x1"æ—¶éšè—æ ‡ç­¾
            adaptive_direction: adaptive_focuså¸ƒå±€çš„ä¸»äº§å“æ–¹å‘
            å…¶ä»–å‚æ•°: æ‹¼æ¥è®¾ç½®

        è¿”å›:
            æ‹¼æ¥åçš„å›¾ç‰‡batch
        """

        batch_size = images.shape[0]
        mask_batch_size = masks.shape[0]

        # æ£€æŸ¥imageså’Œmasksæ•°é‡æ˜¯å¦åŒ¹é…
        if batch_size != mask_batch_size:
            print(f"âŒ é”™è¯¯: å›¾ç‰‡æ•°é‡({batch_size})ä¸maskæ•°é‡({mask_batch_size})ä¸åŒ¹é…")
            # è¿”å›ç©ºç™½å›¾
            empty = np.ones((output_height, output_width, 3), dtype=np.uint8) * 255
            return (self.cv2_to_tensor(empty),)

        total_groups = math.ceil(batch_size / images_per_collage)

        # è§£ææ ‡ç­¾ - æ”¯æŒé€—å·å’Œæ¢è¡Œä¸¤ç§åˆ†éš”æ–¹å¼
        label_list = []
        if labels and labels.strip():
            labels_text = self.preprocess_label(labels.strip())

            # æ£€æµ‹åˆ†éš”ç¬¦ç±»å‹
            if ',' in labels_text:
                # é€—å·åˆ†éš”æ¨¡å¼
                label_list = [self.preprocess_label(label.strip()) for label in labels_text.split(',') if label.strip()]
                print(f"   ğŸ“ æ ‡ç­¾æ•°é‡: {len(label_list)}ä¸ª (é€—å·åˆ†éš”)")
            else:
                # æ¢è¡Œåˆ†éš”æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
                label_list = [self.preprocess_label(line.strip()) for line in labels_text.split('\n') if line.strip()]
                print(f"   ğŸ“ æ ‡ç­¾æ•°é‡: {len(label_list)}ä¸ª (æ¢è¡Œåˆ†éš”)")


        print("\n" + "=" * 70)
        print("ğŸ¨ æ‰¹é‡äº§å“æ‹¼æ¥èŠ‚ç‚¹ v1.8 (å¤–éƒ¨æŠ å›¾ç‰ˆ - ä¿®å¤ç‰ˆ)")
        print("=" * 70)
        print(f"   è¾“å…¥å›¾ç‰‡: {batch_size}å¼ ")
        print(f"   è¾“å…¥masks: {mask_batch_size}å¼ ")
        print(f"   æ¯ç»„æ•°é‡: {images_per_collage}å¼ ")
        print(f"   æ‹¼æ¥ç»„æ•°: {total_groups}ç»„")
        print(f"   è¾“å‡ºå°ºå¯¸: {output_width}x{output_height}px")
        print(f"   å¸ƒå±€æ¨¡å¼: {layout}")
        if layout == "adaptive_focus":
            print(f"   ä¸»äº§å“æ–¹å‘: {adaptive_direction}")
        if label_list:
            print(f"   æ ‡ç­¾ä½ç½®: {label_position}")
            print(f"   æ ‡ç­¾å­—ä½“: {label_font_size}px")
            if hide_pcs_one:
                print(f"   éšè—PCS=1: æ˜¯")
        print("=" * 70)

        # å­˜å‚¨æ‰€æœ‰æ‹¼æ¥ç»“æœ
        collage_results = []

        # æŒ‰ç»„å¤„ç†
        for group_idx in range(total_groups):
            start_idx = group_idx * images_per_collage
            end_idx = min(start_idx + images_per_collage, batch_size)
            group_size = end_idx - start_idx

            print(f"\nğŸ“¦ å¤„ç†ç¬¬{group_idx+1}/{total_groups}ç»„ (å›¾ç‰‡{start_idx+1}-{end_idx})")

            # è·³è¿‡ä¸å®Œæ•´çš„ç»„ï¼ˆå¦‚æœè®¾ç½®äº†skip_emptyï¼‰
            if skip_empty and group_size < images_per_collage:
                print(f"   âš ï¸  è·³è¿‡ä¸å®Œæ•´ç»„ (åªæœ‰{group_size}å¼ )")
                continue

            # æå–å½“å‰ç»„çš„å›¾ç‰‡å’Œmasks
            group_images = images[start_idx:end_idx]
            group_masks = masks[start_idx:end_idx]

            # å¤„ç†å½“å‰ç»„çš„æ¯å¼ å›¾ç‰‡
            products = []
            for i, (img_tensor, mask_tensor) in enumerate(zip(group_images, group_masks)):
                try:
                    # è½¬æ¢ä¸ºOpenCV
                    cv2_img = self.tensor_to_cv2(img_tensor)
                    cv2_mask = self.mask_tensor_to_cv2(mask_tensor)

                    # ğŸ†• ä½¿ç”¨å¤–éƒ¨maskæŠ å›¾ï¼ˆæ›¿ä»£åŸæ¥çš„å»èƒŒæ™¯+æŠ å›¾æµç¨‹ï¼‰
                    product = self.extract_product_with_external_mask(cv2_img, cv2_mask, crop_margin)

                    h, w = product.shape[:2]
                    print(f"   å›¾ç‰‡{i+1}: {w}x{h}px (å·²æŠ å›¾)")

                    products.append(product)

                except Exception as e:
                    print(f"   âŒ å›¾ç‰‡{i+1}å¤„ç†å¤±è´¥: {e}")
                    continue

            if len(products) == 0:
                print(f"   âš ï¸  æœ¬ç»„æ²¡æœ‰æœ‰æ•ˆäº§å“ï¼Œè·³è¿‡")
                continue

            # å†³å®šå¸ƒå±€ï¼ˆä¼ å…¥productsç”¨äºæ™ºèƒ½åˆ¤æ–­ï¼‰
            final_layout = self.decide_layout(len(products), layout, products)
            print(f"   å¸ƒå±€: {final_layout}")

            # ğŸ”§ ä¿®å¤3: æ ¹æ®å¸ƒå±€å’Œäº§å“ç‰¹å¾è°ƒæ•´æ ‡ç­¾ä½ç½®
            final_products = []
            for i, product in enumerate(products):
                # å¤„ç†æ ‡ç­¾ï¼Œæ”¯æŒhide_pcs_oneï¼Œé“¾æ¡äº§å“è‡ªåŠ¨ä½¿ç”¨topä½ç½®
                label = ""
                current_label_position = label_position
                if i < len(label_list):
                    label = label_list[i]

                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥éšè—æ ‡ç­¾
                    if hide_pcs_one:
                        # åŒ¹é… Ã—1, x1, 1ä»¶, 1å¥—, PCS:1 ç­‰æ ¼å¼
                        if re.match(r'^[Ã—x]1$|^1[ä»¶å¥—]$|^PCS:1$', label, re.IGNORECASE):
                            label = ""  # éšè—æ ‡ç­¾
                            print(f"   å›¾ç‰‡{i+1}: æ ‡ç­¾ä¸º1ï¼Œå·²éšè—")

                    # ğŸ”§ ä¿®å¤3: å¦‚æœæ˜¯å‚ç›´å¸ƒå±€ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯é“¾æ¡äº§å“ï¼Œè‡ªåŠ¨æ”¹ä¸ºtopä½ç½®
                    if label and final_layout == "vertical":
                        # æ£€æŸ¥å½“å‰äº§å“æ˜¯å¦æ˜¯é“¾æ¡
                        _, _, _, is_chain = self.get_product_features(product)
                        if is_chain:
                            current_label_position = "top"
                            print(f"   å›¾ç‰‡{i+1}: æ£€æµ‹åˆ°é“¾æ¡ï¼Œæ ‡ç­¾ä½ç½®æ”¹ä¸ºtop")

                if label and current_label_position != "none":
                    product = self.add_label(product, label, current_label_position,
                                           label_font_size, label_margin)
                    h, w = product.shape[:2]
                    print(f"   å›¾ç‰‡{i+1}: {w}x{h}px (å«æ ‡ç­¾: '{label}', ä½ç½®: {current_label_position})")
                else:
                    h, w = product.shape[:2]
                    print(f"   å›¾ç‰‡{i+1}: {w}x{h}px")

                final_products.append(product)

            if len(final_products) == 0:
                print(f"   âš ï¸  æœ¬ç»„æ²¡æœ‰æœ‰æ•ˆäº§å“ï¼Œè·³è¿‡")
                continue

            # åˆ›å»ºæ‹¼æ¥å›¾
            try:
                collage = self.create_collage(final_products, final_layout, output_width, output_height,
                                            spacing, outer_padding, product_scale, adaptive_direction, min_spacing)
                
                # è½¬æ¢ä¸ºtensor
                collage_tensor = self.cv2_to_tensor(collage)
                collage_results.append(collage_tensor)
                
                print(f"   âœ… æ‹¼æ¥å®Œæˆ")
                
            except Exception as e:
                print(f"   âŒ æ‹¼æ¥å¤±è´¥: {e}")
                continue
        
        if len(collage_results) == 0:
            print(f"\nâŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ‹¼æ¥å›¾")
            # è¿”å›ç©ºç™½å›¾
            empty = np.ones((output_height, output_width, 3), dtype=np.uint8) * 255
            return (self.cv2_to_tensor(empty),)
        
        # åˆå¹¶æ‰€æœ‰æ‹¼æ¥ç»“æœ
        final_batch = torch.cat(collage_results, dim=0)
        
        print(f"\nâœ… æ‰¹é‡æ‹¼æ¥å®Œæˆ!")
        print(f"   è¾“å‡º: {final_batch.shape[0]}å¼ æ‹¼æ¥å›¾")
        print("=" * 70 + "\n")
        
        return (final_batch,)


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "SmartProductCollageBatch": SmartProductCollageBatch,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SmartProductCollageBatch": "æ™ºèƒ½äº§å“æ‹¼æ¥Â·å¤–éƒ¨æŠ å›¾ç‰ˆv1.8ğŸ”âœ¨",
}